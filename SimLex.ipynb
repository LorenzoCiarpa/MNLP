{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialization**"
      ],
      "metadata": {
        "id": "VTi0px9nRJbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "BuC3IOj5od_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQkf8D533vFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9497beec-cdb4-4923-9da8-d6009785fe1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=505fefafd3c3762ea1dca8b61f3e130f4e221f096b3fadaba53cb0fb85f84e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.6.1-py3-none-any.whl (881 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.8.0 stanza-1.6.1\n",
            "2023-11-19 18:44:14.000675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-19 18:44:14.000768: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-19 18:44:14.000807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-19 18:44:14.011606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-19 18:44:15.475323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install wget # to download data\n",
        "!pip install spacy\n",
        "!pip install stanza\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec senses\n",
        "!gdown 1kxTudSyCMpzpg6-s1uciVK5Z8PUsDqLz\n",
        "!gdown 10D23CiPOstqaQ4WFRjOL4A2aWPMM8Uj8\n",
        "!gdown 1GrpLOFngEQmL9likQQbQZN9ub29phCuX\n",
        "\n",
        "#word2vec texts\n",
        "!gdown 1Yrhr8Pnz_g0hErCICNolRhinpqmE7t53\n",
        "!gdown 1m7MZhGTfCEQR5V4xxOLJql_4Dv0AvEr2\n",
        "!gdown 1ehuBQfusMFSp9YVasUzol0Exsn7SL-nO\n",
        "\n",
        "# #all sentences of texts\n",
        "# !gdown 16WFM75NRsnC_8pa9jciqI86pNRbiUfTM\n",
        "# !gdown 1zXfgBkfTRuSL9nj5isGc84ih9gA2pYrx\n",
        "# !gdown 15Ms4-mc_pH5sFXW9gSLJ09myN3ss1BlY\n",
        "\n",
        "# #all sentences of senses\n",
        "# !gdown 1Aj6Y9rZklE_A9QaN4woZiJmXjkKc1o5d\n",
        "# !gdown 1lyouL9fZ83VwtLXD0kpNNbFMhqDOulqA\n",
        "# !gdown 1loexh482UWdrmCIkQ-GemhzhPDXHlBkd\n",
        "\n",
        "#complete sentences of texts\n",
        "!gdown 1p31gJM2XReRLr0IVcM5paAvGSbLdso4f\n",
        "\n",
        "#complete sentences of senses\n",
        "!gdown 1VKAxKjgyjxzrg6NVMijE3Y4hzmTia2dl\n",
        "\n",
        "#sense vocabulary\n",
        "!gdown 1hetCmcL70ARK_X52Xr29fljXAO2bR5E5\n",
        "\n",
        "#text vocabulary\n",
        "!gdown 1t4uOtWXHlhJX6j8acdTyMdNBoWLimVz4\n",
        "\n",
        "#semantic simlex\n",
        "!gdown 15-stZizi2qG-xZex2EskIedcrGO_QgLT\n",
        "\n",
        "#mosaico\n",
        "!gdown 1c09qcXS635xURGN0sa1fdbt7OCqLJ-9x\n"
      ],
      "metadata": {
        "id": "yvqlNdW6-KXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e120633a-2152-4af4-a206-21c7f5aab491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kxTudSyCMpzpg6-s1uciVK5Z8PUsDqLz\n",
            "To: /content/model_word2vec_sense_300.bin\n",
            "100% 9.38M/9.38M [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10D23CiPOstqaQ4WFRjOL4A2aWPMM8Uj8\n",
            "To: /content/model_word2vec_sense_300.bin.syn1neg.npy\n",
            "100% 347M/347M [00:04<00:00, 71.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GrpLOFngEQmL9likQQbQZN9ub29phCuX\n",
            "To: /content/model_word2vec_sense_300.bin.wv.vectors.npy\n",
            "100% 347M/347M [00:05<00:00, 65.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yrhr8Pnz_g0hErCICNolRhinpqmE7t53\n",
            "To: /content/model_word2vec_text_300.bin\n",
            "100% 9.16M/9.16M [00:00<00:00, 36.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1m7MZhGTfCEQR5V4xxOLJql_4Dv0AvEr2\n",
            "To: /content/model_word2vec_text_300.bin.syn1neg.npy\n",
            "100% 341M/341M [00:05<00:00, 65.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ehuBQfusMFSp9YVasUzol0Exsn7SL-nO\n",
            "To: /content/model_word2vec_text_300.bin.wv.vectors.npy\n",
            "100% 341M/341M [00:04<00:00, 69.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p31gJM2XReRLr0IVcM5paAvGSbLdso4f\n",
            "To: /content/word_texts_complete.txt\n",
            "100% 87.9M/87.9M [00:01<00:00, 79.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VKAxKjgyjxzrg6NVMijE3Y4hzmTia2dl\n",
            "To: /content/sense_texts_complete.txt\n",
            "100% 107M/107M [00:01<00:00, 76.8MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hetCmcL70ARK_X52Xr29fljXAO2bR5E5\n",
            "To: /content/sense_vocabulary.txt\n",
            "100% 3.42M/3.42M [00:00<00:00, 234MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1t4uOtWXHlhJX6j8acdTyMdNBoWLimVz4\n",
            "To: /content/text_vocabulary.txt\n",
            "100% 3.31M/3.31M [00:00<00:00, 160MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15-stZizi2qG-xZex2EskIedcrGO_QgLT\n",
            "To: /content/semantic_simlex_v0.1.tsv\n",
            "100% 81.3k/81.3k [00:00<00:00, 67.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c09qcXS635xURGN0sa1fdbt7OCqLJ-9x\n",
            "To: /content/500000.jsonl\n",
            "100% 214M/214M [00:01<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhvSJETNFeyN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import wget\n",
        "import ast\n",
        "\n",
        "import spacy\n",
        "import scipy.stats\n",
        "# import stanza\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "import nltk\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmOcaYzZ3arL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# root_folder = '/content/drive/My Drive/Magistrale/EAI/Navigli/Homework-1/' # to save checkpoints\n",
        "# dataset_file = 'sample_annotated_sentences/500000.jsonl' # to save checkpoints\n",
        "# simlex_file = 'semantic_simlex_v0.1/semantic_simlex_v0.1.tsv' # to save checkpoints\n",
        "\n",
        "# dataset_path = os.path.join(root_folder, dataset_file)\n",
        "# simlex_path = os.path.join(root_folder, simlex_file)\n",
        "\n",
        "dataset_path = '500000.jsonl'\n",
        "simlex_path = 'semantic_simlex_v0.1.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRXwaQiE6024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9ea214-b670-428b-8ff5-a46f427ee1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# stanza.download('en')\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# nlp_stanza = stanza.Pipeline('en')\n",
        "\n",
        "regexp_alphbetic = re.compile('[^a-zA-Z]+')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepocessing"
      ],
      "metadata": {
        "id": "oHmotf1RThrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGOwmaxK5-b-"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sentence, reg_stop=False, lemmatize=True):\n",
        "  doc = nlp(sentence)\n",
        "  sentence_tokens = []\n",
        "  for token in doc:\n",
        "    token_text = token.lemma_ if lemmatize else token.text\n",
        "    token_text = token_text.lower()\n",
        "\n",
        "    if reg_stop and (token_text in stop_words or regexp_alphbetic.search(token_text)):\n",
        "      continue\n",
        "\n",
        "    sentence_tokens.append(token_text)\n",
        "  return sentence_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_sense_def(sentence_dic, reg_stop=True, lemmatize=True):\n",
        "  sentence = sentence_dic['text']\n",
        "  doc = nlp(sentence)\n",
        "  doc_splitted = sentence.split()\n",
        "  # count_world = 0\n",
        "  diff_len = len(doc) - len(doc_splitted)\n",
        "\n",
        "  window_bias = 2\n",
        "\n",
        "  sentence_tokens = []\n",
        "  idx_seen = {}\n",
        "  idx_seen_nlp = {}\n",
        "  # idx_seen_dataset = {}\n",
        "\n",
        "  for idx_annotation, annotation in enumerate(sentence_dic['annotations']):\n",
        "    idx_to_change = annotation['token_span'][0]\n",
        "    sense_label = annotation['label']\n",
        "\n",
        "    idx_seen[idx_to_change] = sense_label\n",
        "\n",
        "\n",
        "  for token_idx, token in enumerate(doc):\n",
        "\n",
        "    if token_idx in idx_seen:\n",
        "      window = doc[token_idx: token_idx + diff_len + window_bias + 1]\n",
        "      # print(f'token_idx: {token_idx}, window: {window}')\n",
        "\n",
        "      for idx_sub_tok, sub_tok in enumerate(window):\n",
        "        token_text = sub_tok.lemma_ if lemmatize else sub_tok.text\n",
        "        token_text = token_text.lower()\n",
        "\n",
        "\n",
        "\n",
        "        if token_text == idx_seen[token_idx].split('%')[0]:\n",
        "\n",
        "          idx_seen_nlp[token_idx+idx_sub_tok] = idx_seen[token_idx]\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "  for token_idx, token in enumerate(doc):\n",
        "    token_text = token.lemma_ if lemmatize else token.text\n",
        "    token_text = token_text.lower()\n",
        "\n",
        "    if token_idx in idx_seen_nlp:\n",
        "\n",
        "      if token_text == idx_seen_nlp[token_idx].split('%')[0]:\n",
        "        sentence_tokens.append(idx_seen_nlp[token_idx])\n",
        "        continue\n",
        "\n",
        "    if reg_stop and (token_text in stop_words or regexp_alphbetic.search(token_text)):\n",
        "      continue\n",
        "\n",
        "    sentence_tokens.append(token_text)\n",
        "  return sentence_tokens\n"
      ],
      "metadata": {
        "id": "qLfLN-EfRxBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a_7KuYYFezG"
      },
      "source": [
        "### Loading an existing corpus\n",
        "\n",
        "We can load some existing text and train a model on it.  In this case, we're going to use which is a small subset of Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_path = \"500000.jsonl\"\n",
        "\n",
        "# corpus = []\n",
        "\n",
        "# #we limit the documents for time constrains\n",
        "# MAX_LINES = 534300\n",
        "\n",
        "# with open(train_data_path) as fr:\n",
        "#   count = 0\n",
        "#   for line in tqdm(fr, total = MAX_LINES, leave = True):\n",
        "\n",
        "#     # print(line)\n",
        "#     sentence = json.loads(line)\n",
        "#     corpus.append(sentence)\n",
        "\n",
        "#     count += 1\n",
        "#     if count >= MAX_LINES:\n",
        "#       break\n",
        "\n",
        "# # print(len(corpus))\n",
        "# # print(corpus)"
      ],
      "metadata": {
        "id": "GFiCm3Oy5SJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# homeworks_text = []\n",
        "# sense_texts_def = []\n",
        "\n",
        "# for idx, line in enumerate(tqdm(corpus, total = MAX_LINES, leave = True)):\n",
        "#   homeworks_text.append(preprocess_text(line['text'], True))\n",
        "#   # sense_texts_def.append(preprocess_text_sense_def(line, True))\n",
        "\n"
      ],
      "metadata": {
        "id": "c3_4V8gZ6Y80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'nsense_texts_def: {sense_texts_def[:5]}, \\nhomeworks_text: {homeworks_text[:5]}')\n"
      ],
      "metadata": {
        "id": "n5uxJmxr7JSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Preprocessed sentences"
      ],
      "metadata": {
        "id": "QrpWmWnMFvHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"word_texts_complete.txt\"\n",
        "\n",
        "corpus = []\n",
        "\n",
        "#we limit the documents for time constrains\n",
        "MAX_LINES = 534300\n",
        "\n",
        "with open(train_data_path) as fr:\n",
        "  count = 0\n",
        "  for line in tqdm(fr, total = MAX_LINES, leave = True):\n",
        "    sent = ast.literal_eval(line)\n",
        "    # print(sent[0])\n",
        "    # sentence = json.loads(line)\n",
        "    corpus.append(sent)\n",
        "\n",
        "    count += 1\n",
        "    if count >= MAX_LINES:\n",
        "      break\n",
        "\n",
        "print(len(corpus))\n",
        "\n",
        "homeworks_text = corpus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbrJ24DbKt5X",
        "outputId": "010343b1-48dd-4219-8ee4-a860155dc8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 534300/550000 [00:30<00:00, 17378.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "534300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"sense_texts_complete.txt\"\n",
        "\n",
        "corpus = []\n",
        "\n",
        "#we limit the documents for time constrains\n",
        "MAX_LINES = 200000\n",
        "\n",
        "with open(train_data_path) as fr:\n",
        "  count = 0\n",
        "  for line in tqdm(fr, total = MAX_LINES, leave = True):\n",
        "    sent = ast.literal_eval(line)\n",
        "    # print(sent[0])\n",
        "    # sentence = json.loads(line)\n",
        "    corpus.append(sent)\n",
        "\n",
        "    count += 1\n",
        "    if count >= MAX_LINES:\n",
        "      break\n",
        "\n",
        "print(len(corpus))\n",
        "\n",
        "sense_texts_def = corpus\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69eqs2cmF_VZ",
        "outputId": "a5a0f169-b5e7-4fcb-83ba-2a8937d6a9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 199999/200000 [00:11<00:00, 17333.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save sentences on file"
      ],
      "metadata": {
        "id": "1qKeU-EUm-l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word_filename = 'word_texts_from_200k_to_400k.txt'\n",
        "# sense_filename = 'sense_texts_from_200k_to_400k.txt'\n",
        "\n",
        "# with open(word_filename, 'w') as file:\n",
        "#     # Scrivi ogni frase seguita da un carattere di nuova riga\n",
        "#     for sentence in homeworks_text:\n",
        "#         file.write(f'{sentence}' + '\\n')\n",
        "\n",
        "# with open(sense_filename, 'w') as file:\n",
        "#     # Scrivi ogni frase seguita da un carattere di nuova riga\n",
        "#     for sentence in sense_texts_def:\n",
        "#         file.write(f'{sentence}' + '\\n')\n"
      ],
      "metadata": {
        "id": "grpXeNy7mN3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create word2vec models"
      ],
      "metadata": {
        "id": "xToj05uVSL58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MJQDoLYFezO"
      },
      "outputs": [],
      "source": [
        "# # Using small numbers here, probably want to use a bigger corpus, bigger dimensions, and more iterations.\n",
        "# model_word2vec_text = gensim.models.Word2Vec(homeworks_text, vector_size=300, window=4, epochs=20, min_count=1)\n",
        "# model_word2vec_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using small numbers here, probably want to use a bigger corpus, bigger dimensions, and more iterations.\n",
        "# model_word2vec_sense = gensim.models.Word2Vec(sense_texts_def, vector_size=300, window=4, epochs=20, min_count=1)\n",
        "# model_word2vec_sense"
      ],
      "metadata": {
        "id": "OzWCDDEguw8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_word2vec_text.save(\"model_word2vec_text_300.bin\")\n",
        "# model_word2vec_sense.save(\"model_word2vec_sense_300.bin\")\n",
        "\n",
        "model_word2vec_text = gensim.models.Word2Vec.load(\"model_word2vec_text_300.bin\")\n",
        "model_word2vec_sense = gensim.models.Word2Vec.load(\"model_word2vec_sense_300.bin\")\n"
      ],
      "metadata": {
        "id": "iGLwiB6YIcIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRD9XLxMFezV"
      },
      "outputs": [],
      "source": [
        "# print(model_word2vec_text.wv.most_similar(\"new\"))\n",
        "# print(model_word2vec_sense.wv.most_similar(\"new\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6hKtEnJFeza"
      },
      "outputs": [],
      "source": [
        "# print(model_word2vec_text.wv['new'])\n",
        "# print(model_word2vec_sense.wv['new'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vocabulary = model_word2vec_text.wv.index_to_key\n",
        "# print(text_vocabulary)\n",
        "print(len(text_vocabulary))"
      ],
      "metadata": {
        "id": "U96LlUQLu5C5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f694598d-4ab5-4b53-b2d0-2412d7753f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "284044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sense_vocabulary = model_word2vec_sense.wv.index_to_key\n",
        "# print(sense_vocabulary)\n",
        "print(len(sense_vocabulary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc7fXjfkpOJm",
        "outputId": "a671bc25-3827-401d-c38e-c9508e9bb117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "289408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_filename = 'text_vocabulary.txt'\n",
        "# sense_filename = 'sense_vocabulary.txt'\n",
        "\n",
        "# with open(word_filename, 'w') as file:\n",
        "#     # Scrivi ogni frase seguita da un carattere di nuova riga\n",
        "\n",
        "#     file.write(f'{text_vocabulary}')\n",
        "\n",
        "# with open(sense_filename, 'w') as file:\n",
        "#     # Scrivi ogni frase seguita da un carattere di nuova riga\n",
        "\n",
        "#     file.write(f'{sense_vocabulary}' + '\\n')\n"
      ],
      "metadata": {
        "id": "UxFyNKFi2TEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implicit**"
      ],
      "metadata": {
        "id": "oRj6gq6wFdLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate files to deliver"
      ],
      "metadata": {
        "id": "R3GHsfCMoudg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resulting_file(word2score, filename = 'semantic.tsv'):\n",
        "\n",
        "  with open(filename, 'w') as file:\n",
        "\n",
        "    for word_pair, score in word2score.items():\n",
        "        file.write(f'{word_pair[0]}\\t{word_pair[1]}\\t{score}\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "mpOXWVnMotsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiZbTr2tFez8"
      },
      "source": [
        "### SimLex999\n",
        "\n",
        "As we saw in the slides, we can visualize the distance between words using T-SNE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzmDzeawGCXM"
      },
      "outputs": [],
      "source": [
        "simlex_data = wget.download(\"https://fh295.github.io/SimLex-999.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCp6758UGHb0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "simple_simlex_path = \"simlex999.txt\"\n",
        "\n",
        "simplex_pairs = dict()\n",
        "with zipfile.ZipFile(simlex_data, 'r') as zip, open(simple_simlex_path, \"wb\") as fw:\n",
        "   with zip.open('SimLex-999/SimLex-999.txt') as myfile:\n",
        "    next(myfile)\n",
        "    for line in myfile:\n",
        "      w1, w2, pos, score, *_ = line.strip().split()\n",
        "      simplex_pairs[(w1.decode('utf-8'), w2.decode('utf-8'))] = float(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32k6_x5mG2Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41d8206-63dd-45a2-9544-cf178b1192ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('old', 'new'): 1.58,\n",
              " ('smart', 'intelligent'): 9.2,\n",
              " ('hard', 'difficult'): 8.77,\n",
              " ('happy', 'cheerful'): 9.55,\n",
              " ('hard', 'easy'): 0.95,\n",
              " ('fast', 'rapid'): 8.75,\n",
              " ('happy', 'glad'): 9.17,\n",
              " ('short', 'long'): 1.23,\n",
              " ('stupid', 'dumb'): 9.58,\n",
              " ('weird', 'strange'): 8.93,\n",
              " ('wide', 'narrow'): 1.03,\n",
              " ('bad', 'awful'): 8.42,\n",
              " ('easy', 'difficult'): 0.58,\n",
              " ('bad', 'terrible'): 7.78,\n",
              " ('hard', 'simple'): 1.38,\n",
              " ('smart', 'dumb'): 0.55,\n",
              " ('insane', 'crazy'): 9.57,\n",
              " ('happy', 'mad'): 0.95,\n",
              " ('large', 'huge'): 9.47,\n",
              " ('hard', 'tough'): 8.05,\n",
              " ('new', 'fresh'): 6.83,\n",
              " ('sharp', 'dull'): 0.6,\n",
              " ('quick', 'rapid'): 9.7,\n",
              " ('dumb', 'foolish'): 6.67,\n",
              " ('wonderful', 'terrific'): 8.63,\n",
              " ('strange', 'odd'): 9.02,\n",
              " ('happy', 'angry'): 1.28,\n",
              " ('narrow', 'broad'): 1.18,\n",
              " ('simple', 'easy'): 9.4,\n",
              " ('old', 'fresh'): 0.87,\n",
              " ('apparent', 'obvious'): 8.47,\n",
              " ('inexpensive', 'cheap'): 8.72,\n",
              " ('nice', 'generous'): 5.0,\n",
              " ('weird', 'normal'): 0.72,\n",
              " ('weird', 'odd'): 9.2,\n",
              " ('bad', 'immoral'): 7.62,\n",
              " ('sad', 'funny'): 0.95,\n",
              " ('wonderful', 'great'): 8.05,\n",
              " ('guilty', 'ashamed'): 6.38,\n",
              " ('beautiful', 'wonderful'): 6.5,\n",
              " ('confident', 'sure'): 8.27,\n",
              " ('dumb', 'dense'): 7.27,\n",
              " ('large', 'big'): 9.55,\n",
              " ('nice', 'cruel'): 0.67,\n",
              " ('impatient', 'anxious'): 6.03,\n",
              " ('big', 'broad'): 6.73,\n",
              " ('strong', 'proud'): 3.17,\n",
              " ('unnecessary', 'necessary'): 0.63,\n",
              " ('restless', 'young'): 1.6,\n",
              " ('dumb', 'intelligent'): 0.75,\n",
              " ('bad', 'great'): 0.35,\n",
              " ('difficult', 'simple'): 0.87,\n",
              " ('necessary', 'important'): 7.37,\n",
              " ('bad', 'terrific'): 0.65,\n",
              " ('mad', 'glad'): 1.45,\n",
              " ('honest', 'guilty'): 1.18,\n",
              " ('easy', 'tough'): 0.52,\n",
              " ('easy', 'flexible'): 4.1,\n",
              " ('certain', 'sure'): 8.42,\n",
              " ('essential', 'necessary'): 8.97,\n",
              " ('different', 'normal'): 1.08,\n",
              " ('sly', 'clever'): 7.25,\n",
              " ('crucial', 'important'): 8.82,\n",
              " ('harsh', 'cruel'): 8.18,\n",
              " ('childish', 'foolish'): 5.5,\n",
              " ('scarce', 'rare'): 9.17,\n",
              " ('friendly', 'generous'): 5.9,\n",
              " ('fragile', 'frigid'): 2.38,\n",
              " ('long', 'narrow'): 3.57,\n",
              " ('big', 'heavy'): 6.18,\n",
              " ('rough', 'frigid'): 2.47,\n",
              " ('bizarre', 'strange'): 9.37,\n",
              " ('illegal', 'immoral'): 4.28,\n",
              " ('bad', 'guilty'): 4.2,\n",
              " ('modern', 'ancient'): 0.73,\n",
              " ('new', 'ancient'): 0.23,\n",
              " ('dull', 'funny'): 0.55,\n",
              " ('happy', 'young'): 2.0,\n",
              " ('easy', 'big'): 1.12,\n",
              " ('great', 'awful'): 1.17,\n",
              " ('tiny', 'huge'): 0.6,\n",
              " ('polite', 'proper'): 7.63,\n",
              " ('modest', 'ashamed'): 2.65,\n",
              " ('exotic', 'rare'): 8.05,\n",
              " ('dumb', 'clever'): 1.17,\n",
              " ('delightful', 'wonderful'): 8.65,\n",
              " ('noticeable', 'obvious'): 8.48,\n",
              " ('afraid', 'anxious'): 5.07,\n",
              " ('formal', 'proper'): 8.02,\n",
              " ('dreary', 'dull'): 8.25,\n",
              " ('delightful', 'cheerful'): 6.58,\n",
              " ('unhappy', 'mad'): 5.95,\n",
              " ('sad', 'terrible'): 5.4,\n",
              " ('sick', 'crazy'): 3.57,\n",
              " ('violent', 'angry'): 6.98,\n",
              " ('laden', 'heavy'): 5.9,\n",
              " ('dirty', 'cheap'): 1.6,\n",
              " ('elastic', 'flexible'): 7.78,\n",
              " ('hard', 'dense'): 5.9,\n",
              " ('recent', 'new'): 7.05,\n",
              " ('bold', 'proud'): 3.97,\n",
              " ('sly', 'strange'): 1.97,\n",
              " ('strange', 'sly'): 2.07,\n",
              " ('dumb', 'rare'): 0.48,\n",
              " ('sly', 'tough'): 0.58,\n",
              " ('terrific', 'mad'): 0.4,\n",
              " ('modest', 'flexible'): 0.98,\n",
              " ('fresh', 'wide'): 0.4,\n",
              " ('huge', 'dumb'): 0.48,\n",
              " ('large', 'flexible'): 0.48,\n",
              " ('dirty', 'narrow'): 0.3,\n",
              " ('wife', 'husband'): 2.3,\n",
              " ('book', 'text'): 6.35,\n",
              " ('groom', 'bride'): 3.17,\n",
              " ('night', 'day'): 1.88,\n",
              " ('south', 'north'): 2.2,\n",
              " ('plane', 'airport'): 3.65,\n",
              " ('uncle', 'aunt'): 5.5,\n",
              " ('horse', 'mare'): 8.33,\n",
              " ('bottom', 'top'): 0.7,\n",
              " ('friend', 'buddy'): 8.78,\n",
              " ('student', 'pupil'): 9.35,\n",
              " ('world', 'globe'): 6.67,\n",
              " ('leg', 'arm'): 2.88,\n",
              " ('plane', 'jet'): 8.1,\n",
              " ('woman', 'man'): 3.33,\n",
              " ('horse', 'colt'): 7.07,\n",
              " ('actress', 'actor'): 7.12,\n",
              " ('teacher', 'instructor'): 9.25,\n",
              " ('movie', 'film'): 8.87,\n",
              " ('bird', 'hawk'): 7.85,\n",
              " ('word', 'dictionary'): 3.68,\n",
              " ('money', 'salary'): 7.88,\n",
              " ('dog', 'cat'): 1.75,\n",
              " ('area', 'region'): 9.47,\n",
              " ('navy', 'army'): 6.43,\n",
              " ('book', 'literature'): 7.53,\n",
              " ('clothes', 'closet'): 3.27,\n",
              " ('sunset', 'sunrise'): 2.47,\n",
              " ('child', 'adult'): 2.98,\n",
              " ('cow', 'cattle'): 9.52,\n",
              " ('book', 'story'): 5.63,\n",
              " ('winter', 'summer'): 2.38,\n",
              " ('taxi', 'cab'): 9.2,\n",
              " ('tree', 'maple'): 5.53,\n",
              " ('bed', 'bedroom'): 3.4,\n",
              " ('roof', 'ceiling'): 7.58,\n",
              " ('disease', 'infection'): 7.15,\n",
              " ('arm', 'shoulder'): 4.85,\n",
              " ('sheep', 'lamb'): 8.42,\n",
              " ('lady', 'gentleman'): 3.42,\n",
              " ('boat', 'anchor'): 2.25,\n",
              " ('priest', 'monk'): 6.28,\n",
              " ('toe', 'finger'): 4.68,\n",
              " ('river', 'stream'): 7.3,\n",
              " ('anger', 'fury'): 8.73,\n",
              " ('date', 'calendar'): 4.42,\n",
              " ('sea', 'ocean'): 8.27,\n",
              " ('second', 'minute'): 4.62,\n",
              " ('hand', 'thumb'): 3.88,\n",
              " ('wood', 'log'): 7.3,\n",
              " ('mud', 'dirt'): 7.32,\n",
              " ('hallway', 'corridor'): 9.28,\n",
              " ('way', 'manner'): 7.62,\n",
              " ('mouse', 'cat'): 1.12,\n",
              " ('cop', 'sheriff'): 9.05,\n",
              " ('death', 'burial'): 4.93,\n",
              " ('music', 'melody'): 6.98,\n",
              " ('beer', 'alcohol'): 7.5,\n",
              " ('mouth', 'lip'): 7.1,\n",
              " ('storm', 'hurricane'): 6.38,\n",
              " ('tax', 'income'): 2.38,\n",
              " ('flower', 'violet'): 6.95,\n",
              " ('paper', 'cardboard'): 5.38,\n",
              " ('floor', 'ceiling'): 1.73,\n",
              " ('beach', 'seashore'): 8.33,\n",
              " ('rod', 'curtain'): 3.03,\n",
              " ('hound', 'fox'): 2.38,\n",
              " ('street', 'alley'): 5.48,\n",
              " ('boat', 'deck'): 4.28,\n",
              " ('car', 'horn'): 2.57,\n",
              " ('friend', 'guest'): 4.25,\n",
              " ('employer', 'employee'): 3.65,\n",
              " ('hand', 'wrist'): 3.97,\n",
              " ('ball', 'cannon'): 2.58,\n",
              " ('alcohol', 'brandy'): 6.98,\n",
              " ('victory', 'triumph'): 8.98,\n",
              " ('telephone', 'booth'): 3.63,\n",
              " ('door', 'doorway'): 5.4,\n",
              " ('motel', 'inn'): 8.17,\n",
              " ('clothes', 'cloth'): 5.47,\n",
              " ('steak', 'meat'): 7.47,\n",
              " ('nail', 'thumb'): 3.55,\n",
              " ('band', 'orchestra'): 7.08,\n",
              " ('book', 'bible'): 5.0,\n",
              " ('business', 'industry'): 7.02,\n",
              " ('winter', 'season'): 6.27,\n",
              " ('decade', 'century'): 3.48,\n",
              " ('alcohol', 'gin'): 8.65,\n",
              " ('hat', 'coat'): 2.67,\n",
              " ('window', 'door'): 3.33,\n",
              " ('arm', 'wrist'): 3.57,\n",
              " ('house', 'apartment'): 5.8,\n",
              " ('glass', 'crystal'): 6.27,\n",
              " ('wine', 'brandy'): 5.15,\n",
              " ('creator', 'maker'): 9.62,\n",
              " ('dinner', 'breakfast'): 3.33,\n",
              " ('arm', 'muscle'): 3.72,\n",
              " ('bubble', 'suds'): 8.57,\n",
              " ('bread', 'flour'): 3.33,\n",
              " ('death', 'tragedy'): 5.8,\n",
              " ('absence', 'presence'): 0.4,\n",
              " ('gun', 'cannon'): 5.68,\n",
              " ('grass', 'blade'): 4.57,\n",
              " ('ball', 'basket'): 1.67,\n",
              " ('hose', 'garden'): 1.67,\n",
              " ('boy', 'kid'): 7.5,\n",
              " ('church', 'choir'): 2.95,\n",
              " ('clothes', 'drawer'): 3.02,\n",
              " ('tower', 'bell'): 1.9,\n",
              " ('father', 'parent'): 7.07,\n",
              " ('school', 'grade'): 4.42,\n",
              " ('parent', 'adult'): 5.37,\n",
              " ('bar', 'jail'): 1.9,\n",
              " ('car', 'highway'): 3.4,\n",
              " ('dictionary', 'definition'): 6.25,\n",
              " ('door', 'cellar'): 1.97,\n",
              " ('army', 'legion'): 5.95,\n",
              " ('metal', 'aluminum'): 7.25,\n",
              " ('chair', 'bench'): 6.67,\n",
              " ('cloud', 'fog'): 6.0,\n",
              " ('boy', 'son'): 6.75,\n",
              " ('water', 'ice'): 6.47,\n",
              " ('bed', 'blanket'): 3.02,\n",
              " ('attorney', 'lawyer'): 9.35,\n",
              " ('area', 'zone'): 8.33,\n",
              " ('business', 'company'): 9.02,\n",
              " ('clothes', 'fabric'): 5.87,\n",
              " ('sweater', 'jacket'): 7.15,\n",
              " ('money', 'capital'): 6.67,\n",
              " ('hand', 'foot'): 4.17,\n",
              " ('alcohol', 'cocktail'): 6.73,\n",
              " ('yard', 'inch'): 3.78,\n",
              " ('molecule', 'atom'): 6.45,\n",
              " ('lens', 'camera'): 4.28,\n",
              " ('meal', 'dinner'): 7.15,\n",
              " ('eye', 'tear'): 3.55,\n",
              " ('god', 'devil'): 1.8,\n",
              " ('loop', 'belt'): 3.1,\n",
              " ('rat', 'mouse'): 7.78,\n",
              " ('motor', 'engine'): 8.65,\n",
              " ('car', 'cab'): 7.42,\n",
              " ('cat', 'lion'): 6.75,\n",
              " ('size', 'magnitude'): 6.33,\n",
              " ('reality', 'fantasy'): 1.03,\n",
              " ('door', 'gate'): 5.25,\n",
              " ('cat', 'pet'): 5.95,\n",
              " ('tin', 'aluminum'): 6.42,\n",
              " ('bone', 'jaw'): 4.17,\n",
              " ('cereal', 'wheat'): 3.75,\n",
              " ('house', 'key'): 1.9,\n",
              " ('blood', 'flesh'): 4.28,\n",
              " ('door', 'corridor'): 3.73,\n",
              " ('god', 'spirit'): 7.3,\n",
              " ('capability', 'competence'): 7.62,\n",
              " ('abundance', 'plenty'): 8.97,\n",
              " ('sofa', 'chair'): 6.67,\n",
              " ('wall', 'brick'): 4.68,\n",
              " ('horn', 'drum'): 2.68,\n",
              " ('organ', 'liver'): 6.15,\n",
              " ('strength', 'might'): 7.07,\n",
              " ('phrase', 'word'): 5.48,\n",
              " ('band', 'parade'): 3.92,\n",
              " ('stomach', 'waist'): 5.9,\n",
              " ('cloud', 'storm'): 5.6,\n",
              " ('joy', 'pride'): 5.0,\n",
              " ('noise', 'rattle'): 6.17,\n",
              " ('rain', 'mist'): 5.97,\n",
              " ('beer', 'beverage'): 5.42,\n",
              " ('man', 'uncle'): 3.92,\n",
              " ('apple', 'juice'): 2.88,\n",
              " ('intelligence', 'logic'): 6.5,\n",
              " ('communication', 'language'): 7.47,\n",
              " ('mink', 'fur'): 6.83,\n",
              " ('mob', 'crowd'): 7.85,\n",
              " ('shore', 'coast'): 8.83,\n",
              " ('wire', 'cord'): 7.62,\n",
              " ('bird', 'turkey'): 6.58,\n",
              " ('bed', 'crib'): 7.3,\n",
              " ('competence', 'ability'): 7.5,\n",
              " ('cloud', 'haze'): 7.32,\n",
              " ('supper', 'meal'): 7.53,\n",
              " ('bar', 'cage'): 2.8,\n",
              " ('water', 'salt'): 1.3,\n",
              " ('sense', 'intuition'): 7.68,\n",
              " ('situation', 'condition'): 6.58,\n",
              " ('crime', 'theft'): 7.53,\n",
              " ('style', 'fashion'): 8.5,\n",
              " ('boundary', 'border'): 9.08,\n",
              " ('arm', 'body'): 4.05,\n",
              " ('boat', 'car'): 2.37,\n",
              " ('sandwich', 'lunch'): 6.3,\n",
              " ('bride', 'princess'): 2.8,\n",
              " ('heroine', 'hero'): 8.78,\n",
              " ('car', 'gauge'): 1.13,\n",
              " ('insect', 'bee'): 6.07,\n",
              " ('crib', 'cradle'): 8.55,\n",
              " ('animal', 'person'): 3.05,\n",
              " ('marijuana', 'herb'): 6.5,\n",
              " ('bed', 'hospital'): 0.92,\n",
              " ('cheek', 'tongue'): 4.52,\n",
              " ('disc', 'computer'): 3.2,\n",
              " ('curve', 'angle'): 3.33,\n",
              " ('grass', 'moss'): 5.0,\n",
              " ('school', 'law'): 1.13,\n",
              " ('foot', 'head'): 2.3,\n",
              " ('mother', 'guardian'): 6.5,\n",
              " ('orthodontist', 'dentist'): 8.27,\n",
              " ('alcohol', 'whiskey'): 7.27,\n",
              " ('mouth', 'tooth'): 6.3,\n",
              " ('breakfast', 'bacon'): 4.37,\n",
              " ('bathroom', 'bedroom'): 3.4,\n",
              " ('plate', 'bowl'): 5.23,\n",
              " ('meat', 'bacon'): 5.8,\n",
              " ('air', 'helium'): 3.63,\n",
              " ('worker', 'employer'): 5.37,\n",
              " ('body', 'chest'): 4.45,\n",
              " ('son', 'father'): 3.82,\n",
              " ('heart', 'surgery'): 1.08,\n",
              " ('woman', 'secretary'): 1.98,\n",
              " ('man', 'father'): 4.83,\n",
              " ('beach', 'island'): 5.6,\n",
              " ('story', 'topic'): 5.0,\n",
              " ('game', 'fun'): 3.42,\n",
              " ('weekend', 'week'): 4.0,\n",
              " ('couple', 'pair'): 8.33,\n",
              " ('woman', 'wife'): 5.72,\n",
              " ('sheep', 'cattle'): 4.77,\n",
              " ('purse', 'bag'): 8.33,\n",
              " ('ceiling', 'cathedral'): 2.42,\n",
              " ('bean', 'coffee'): 5.15,\n",
              " ('wood', 'paper'): 2.88,\n",
              " ('top', 'side'): 1.9,\n",
              " ('crime', 'fraud'): 5.65,\n",
              " ('pain', 'harm'): 5.38,\n",
              " ('lover', 'companion'): 5.97,\n",
              " ('evening', 'dusk'): 7.78,\n",
              " ('father', 'daughter'): 2.62,\n",
              " ('wine', 'liquor'): 7.85,\n",
              " ('cow', 'goat'): 2.93,\n",
              " ('belief', 'opinion'): 7.7,\n",
              " ('reality', 'illusion'): 1.42,\n",
              " ('pact', 'agreement'): 9.02,\n",
              " ('wealth', 'poverty'): 1.27,\n",
              " ('accident', 'emergency'): 4.93,\n",
              " ('battle', 'conquest'): 7.22,\n",
              " ('friend', 'teacher'): 2.62,\n",
              " ('illness', 'infection'): 6.9,\n",
              " ('game', 'trick'): 2.32,\n",
              " ('brother', 'son'): 3.48,\n",
              " ('aunt', 'nephew'): 3.1,\n",
              " ('worker', 'mechanic'): 4.92,\n",
              " ('doctor', 'orthodontist'): 5.58,\n",
              " ('oak', 'maple'): 6.03,\n",
              " ('bee', 'queen'): 3.27,\n",
              " ('car', 'bicycle'): 3.47,\n",
              " ('goal', 'quest'): 5.83,\n",
              " ('august', 'month'): 5.53,\n",
              " ('army', 'squad'): 5.08,\n",
              " ('cloud', 'weather'): 4.87,\n",
              " ('physician', 'doctor'): 8.88,\n",
              " ('canyon', 'valley'): 6.75,\n",
              " ('river', 'valley'): 1.67,\n",
              " ('sun', 'sky'): 2.27,\n",
              " ('target', 'arrow'): 3.25,\n",
              " ('chocolate', 'pie'): 2.27,\n",
              " ('circumstance', 'situation'): 7.85,\n",
              " ('opinion', 'choice'): 5.43,\n",
              " ('rhythm', 'melody'): 6.12,\n",
              " ('gut', 'nerve'): 4.93,\n",
              " ('day', 'dawn'): 5.47,\n",
              " ('cattle', 'beef'): 7.03,\n",
              " ('doctor', 'professor'): 4.65,\n",
              " ('arm', 'vein'): 3.65,\n",
              " ('room', 'bath'): 3.33,\n",
              " ('corporation', 'business'): 9.02,\n",
              " ('fun', 'football'): 1.97,\n",
              " ('hill', 'cliff'): 4.28,\n",
              " ('bone', 'ankle'): 3.82,\n",
              " ('apple', 'candy'): 2.08,\n",
              " ('helper', 'maid'): 5.58,\n",
              " ('leader', 'manager'): 7.27,\n",
              " ('lemon', 'tea'): 1.6,\n",
              " ('bee', 'ant'): 2.78,\n",
              " ('basketball', 'baseball'): 4.92,\n",
              " ('rice', 'bean'): 2.72,\n",
              " ('bed', 'furniture'): 6.08,\n",
              " ('emotion', 'passion'): 7.72,\n",
              " ('anarchy', 'chaos'): 7.93,\n",
              " ('crime', 'violation'): 7.12,\n",
              " ('machine', 'engine'): 5.58,\n",
              " ('beach', 'sea'): 4.68,\n",
              " ('alley', 'bowl'): 1.53,\n",
              " ('jar', 'bottle'): 7.83,\n",
              " ('strength', 'capability'): 5.28,\n",
              " ('seed', 'mustard'): 3.48,\n",
              " ('guitar', 'drum'): 3.78,\n",
              " ('opinion', 'idea'): 5.7,\n",
              " ('north', 'west'): 3.63,\n",
              " ('diet', 'salad'): 2.98,\n",
              " ('mother', 'wife'): 3.02,\n",
              " ('dad', 'mother'): 3.55,\n",
              " ('captain', 'sailor'): 5.0,\n",
              " ('meter', 'yard'): 5.6,\n",
              " ('beer', 'champagne'): 4.45,\n",
              " ('motor', 'boat'): 2.57,\n",
              " ('card', 'bridge'): 1.97,\n",
              " ('science', 'psychology'): 4.92,\n",
              " ('sinner', 'saint'): 1.6,\n",
              " ('destruction', 'construction'): 0.98,\n",
              " ('crowd', 'bunch'): 7.42,\n",
              " ('beach', 'reef'): 3.77,\n",
              " ('man', 'child'): 4.13,\n",
              " ('bread', 'cheese'): 1.95,\n",
              " ('champion', 'winner'): 8.73,\n",
              " ('celebration', 'ceremony'): 7.72,\n",
              " ('menu', 'order'): 3.62,\n",
              " ('king', 'princess'): 3.27,\n",
              " ('wealth', 'prestige'): 6.07,\n",
              " ('endurance', 'strength'): 6.58,\n",
              " ('danger', 'threat'): 8.78,\n",
              " ('god', 'priest'): 4.5,\n",
              " ('men', 'fraternity'): 3.13,\n",
              " ('buddy', 'companion'): 8.65,\n",
              " ('teacher', 'helper'): 4.28,\n",
              " ('body', 'stomach'): 3.93,\n",
              " ('tongue', 'throat'): 3.1,\n",
              " ('house', 'carpet'): 1.38,\n",
              " ('intelligence', 'skill'): 5.35,\n",
              " ('journey', 'conquest'): 4.72,\n",
              " ('god', 'prey'): 1.23,\n",
              " ('brother', 'soul'): 0.97,\n",
              " ('adversary', 'opponent'): 9.05,\n",
              " ('death', 'catastrophe'): 4.13,\n",
              " ('monster', 'demon'): 6.95,\n",
              " ('day', 'morning'): 4.87,\n",
              " ('man', 'victor'): 1.9,\n",
              " ('friend', 'guy'): 3.88,\n",
              " ('song', 'story'): 3.97,\n",
              " ('ray', 'sunshine'): 6.83,\n",
              " ('guy', 'stud'): 5.83,\n",
              " ('chicken', 'rice'): 1.43,\n",
              " ('box', 'elevator'): 1.32,\n",
              " ('butter', 'potato'): 1.22,\n",
              " ('apartment', 'furniture'): 1.28,\n",
              " ('lake', 'swamp'): 4.92,\n",
              " ('salad', 'vinegar'): 1.13,\n",
              " ('flower', 'bulb'): 4.48,\n",
              " ('cloud', 'mist'): 6.67,\n",
              " ('driver', 'pilot'): 6.28,\n",
              " ('sugar', 'honey'): 5.13,\n",
              " ('body', 'shoulder'): 2.88,\n",
              " ('idea', 'image'): 3.55,\n",
              " ('father', 'brother'): 4.2,\n",
              " ('moon', 'planet'): 5.87,\n",
              " ('ball', 'costume'): 2.32,\n",
              " ('rail', 'fence'): 5.22,\n",
              " ('room', 'bed'): 2.35,\n",
              " ('flower', 'bush'): 4.25,\n",
              " ('bone', 'knee'): 4.17,\n",
              " ('arm', 'knee'): 2.75,\n",
              " ('bottom', 'side'): 2.63,\n",
              " ('vessel', 'vein'): 5.15,\n",
              " ('cat', 'rabbit'): 2.37,\n",
              " ('meat', 'sandwich'): 2.35,\n",
              " ('belief', 'concept'): 5.08,\n",
              " ('intelligence', 'insight'): 5.9,\n",
              " ('attention', 'interest'): 7.22,\n",
              " ('attitude', 'confidence'): 4.35,\n",
              " ('right', 'justice'): 7.05,\n",
              " ('argument', 'agreement'): 1.45,\n",
              " ('depth', 'magnitude'): 6.12,\n",
              " ('medium', 'news'): 3.65,\n",
              " ('winner', 'candidate'): 2.78,\n",
              " ('birthday', 'date'): 5.08,\n",
              " ('fee', 'payment'): 7.15,\n",
              " ('bible', 'hymn'): 5.15,\n",
              " ('exit', 'doorway'): 5.5,\n",
              " ('man', 'sentry'): 3.25,\n",
              " ('aisle', 'hall'): 6.35,\n",
              " ('whiskey', 'gin'): 6.28,\n",
              " ('blood', 'marrow'): 3.4,\n",
              " ('oil', 'mink'): 1.23,\n",
              " ('floor', 'deck'): 5.55,\n",
              " ('roof', 'floor'): 2.62,\n",
              " ('door', 'floor'): 1.67,\n",
              " ('shoulder', 'head'): 3.42,\n",
              " ('wagon', 'carriage'): 7.7,\n",
              " ('car', 'carriage'): 5.13,\n",
              " ('elbow', 'ankle'): 3.13,\n",
              " ('wealth', 'fame'): 4.02,\n",
              " ('sorrow', 'shame'): 4.77,\n",
              " ('administration', 'management'): 7.25,\n",
              " ('communication', 'conversation'): 8.02,\n",
              " ('pollution', 'atmosphere'): 4.25,\n",
              " ('anatomy', 'biology'): 5.33,\n",
              " ('college', 'profession'): 3.12,\n",
              " ('book', 'topic'): 2.07,\n",
              " ('formula', 'equation'): 7.95,\n",
              " ('book', 'information'): 5.0,\n",
              " ('boy', 'partner'): 1.9,\n",
              " ('sky', 'universe'): 4.68,\n",
              " ('population', 'people'): 7.68,\n",
              " ('college', 'class'): 4.13,\n",
              " ('chief', 'mayor'): 4.85,\n",
              " ('rabbi', 'minister'): 7.62,\n",
              " ('meter', 'inch'): 5.08,\n",
              " ('polyester', 'cotton'): 5.63,\n",
              " ('lawyer', 'banker'): 1.88,\n",
              " ('violin', 'instrument'): 6.58,\n",
              " ('camp', 'cabin'): 4.2,\n",
              " ('pot', 'appliance'): 2.53,\n",
              " ('linen', 'fabric'): 7.47,\n",
              " ('whiskey', 'champagne'): 5.33,\n",
              " ('girl', 'child'): 5.38,\n",
              " ('cottage', 'cabin'): 7.72,\n",
              " ('bird', 'hen'): 7.03,\n",
              " ('racket', 'noise'): 8.1,\n",
              " ('sunset', 'evening'): 5.98,\n",
              " ('drizzle', 'rain'): 9.17,\n",
              " ('adult', 'baby'): 2.22,\n",
              " ('charcoal', 'coal'): 7.63,\n",
              " ('body', 'spine'): 4.78,\n",
              " ('head', 'nail'): 2.47,\n",
              " ('log', 'timber'): 8.05,\n",
              " ('spoon', 'cup'): 2.02,\n",
              " ('body', 'nerve'): 3.13,\n",
              " ('man', 'husband'): 5.32,\n",
              " ('bone', 'neck'): 2.53,\n",
              " ('frustration', 'anger'): 6.5,\n",
              " ('river', 'sea'): 5.72,\n",
              " ('task', 'job'): 8.87,\n",
              " ('club', 'society'): 5.23,\n",
              " ('reflection', 'image'): 7.27,\n",
              " ('prince', 'king'): 5.92,\n",
              " ('snow', 'weather'): 5.48,\n",
              " ('people', 'party'): 2.2,\n",
              " ('boy', 'brother'): 6.67,\n",
              " ('root', 'grass'): 3.55,\n",
              " ('brow', 'eye'): 3.82,\n",
              " ('money', 'pearl'): 2.1,\n",
              " ('money', 'diamond'): 3.42,\n",
              " ('vehicle', 'bus'): 6.47,\n",
              " ('cab', 'bus'): 5.6,\n",
              " ('house', 'barn'): 4.33,\n",
              " ('finger', 'palm'): 3.33,\n",
              " ('car', 'bridge'): 0.95,\n",
              " ('effort', 'difficulty'): 4.45,\n",
              " ('fact', 'insight'): 4.77,\n",
              " ('job', 'management'): 3.97,\n",
              " ('cancer', 'sickness'): 7.93,\n",
              " ('word', 'newspaper'): 2.47,\n",
              " ('composer', 'writer'): 6.58,\n",
              " ('actor', 'singer'): 4.52,\n",
              " ('shelter', 'hut'): 6.47,\n",
              " ('bathroom', 'kitchen'): 3.1,\n",
              " ('cabin', 'hut'): 6.53,\n",
              " ('door', 'kitchen'): 1.67,\n",
              " ('value', 'belief'): 7.07,\n",
              " ('wisdom', 'intelligence'): 7.47,\n",
              " ('ignorance', 'intelligence'): 1.5,\n",
              " ('happiness', 'luck'): 2.38,\n",
              " ('idea', 'scheme'): 6.75,\n",
              " ('mood', 'emotion'): 8.12,\n",
              " ('happiness', 'peace'): 6.03,\n",
              " ('despair', 'misery'): 7.22,\n",
              " ('logic', 'arithmetic'): 3.97,\n",
              " ('denial', 'confession'): 1.03,\n",
              " ('argument', 'criticism'): 5.08,\n",
              " ('aggression', 'hostility'): 8.48,\n",
              " ('hysteria', 'confusion'): 6.33,\n",
              " ('chemistry', 'theory'): 3.17,\n",
              " ('trial', 'verdict'): 3.33,\n",
              " ('comfort', 'safety'): 5.8,\n",
              " ('confidence', 'self'): 3.12,\n",
              " ('vision', 'perception'): 6.88,\n",
              " ('era', 'decade'): 5.4,\n",
              " ('biography', 'fiction'): 1.38,\n",
              " ('discussion', 'argument'): 5.48,\n",
              " ('code', 'symbol'): 6.03,\n",
              " ('danger', 'disease'): 3.0,\n",
              " ('accident', 'catastrophe'): 5.9,\n",
              " ('journey', 'trip'): 8.88,\n",
              " ('activity', 'movement'): 7.15,\n",
              " ('gossip', 'news'): 5.22,\n",
              " ('father', 'god'): 3.57,\n",
              " ('action', 'course'): 5.45,\n",
              " ('fever', 'illness'): 7.65,\n",
              " ('aviation', 'flight'): 8.18,\n",
              " ('game', 'action'): 4.85,\n",
              " ('molecule', 'air'): 3.05,\n",
              " ('home', 'state'): 2.58,\n",
              " ('word', 'literature'): 4.77,\n",
              " ('adult', 'guardian'): 6.9,\n",
              " ('newspaper', 'information'): 5.65,\n",
              " ('communication', 'television'): 5.6,\n",
              " ('cousin', 'uncle'): 4.63,\n",
              " ('author', 'reader'): 1.6,\n",
              " ('guy', 'partner'): 3.57,\n",
              " ('area', 'corner'): 2.07,\n",
              " ('ballad', 'song'): 7.53,\n",
              " ('wall', 'decoration'): 2.62,\n",
              " ('word', 'page'): 2.92,\n",
              " ('nurse', 'scientist'): 2.08,\n",
              " ('politician', 'president'): 7.38,\n",
              " ('president', 'mayor'): 5.68,\n",
              " ('book', 'essay'): 4.72,\n",
              " ('man', 'warrior'): 4.72,\n",
              " ('article', 'journal'): 6.18,\n",
              " ('breakfast', 'supper'): 4.4,\n",
              " ('crowd', 'parade'): 3.93,\n",
              " ('aisle', 'hallway'): 6.75,\n",
              " ('teacher', 'rabbi'): 4.37,\n",
              " ('hip', 'lip'): 1.43,\n",
              " ('book', 'article'): 5.43,\n",
              " ('room', 'cell'): 4.58,\n",
              " ('box', 'booth'): 3.8,\n",
              " ('daughter', 'kid'): 4.17,\n",
              " ('limb', 'leg'): 6.9,\n",
              " ('liver', 'lung'): 2.7,\n",
              " ('classroom', 'hallway'): 2.0,\n",
              " ('mountain', 'ledge'): 3.73,\n",
              " ('car', 'elevator'): 1.03,\n",
              " ('bed', 'couch'): 3.42,\n",
              " ('clothes', 'button'): 2.3,\n",
              " ('clothes', 'coat'): 5.35,\n",
              " ('kidney', 'organ'): 6.17,\n",
              " ('apple', 'sauce'): 1.43,\n",
              " ('chicken', 'steak'): 3.73,\n",
              " ('car', 'hose'): 0.87,\n",
              " ('tobacco', 'cigarette'): 7.5,\n",
              " ('student', 'professor'): 1.95,\n",
              " ('baby', 'daughter'): 5.0,\n",
              " ('pipe', 'cigar'): 6.03,\n",
              " ('milk', 'juice'): 4.05,\n",
              " ('box', 'cigar'): 1.25,\n",
              " ('apartment', 'hotel'): 3.33,\n",
              " ('cup', 'cone'): 3.17,\n",
              " ('horse', 'ox'): 3.02,\n",
              " ('throat', 'nose'): 2.8,\n",
              " ('bone', 'teeth'): 4.17,\n",
              " ('bone', 'elbow'): 3.78,\n",
              " ('bacon', 'bean'): 1.22,\n",
              " ('cup', 'jar'): 5.13,\n",
              " ('proof', 'fact'): 7.3,\n",
              " ('appointment', 'engagement'): 6.75,\n",
              " ('birthday', 'year'): 1.67,\n",
              " ('word', 'clue'): 2.53,\n",
              " ('author', 'creator'): 8.02,\n",
              " ('atom', 'carbon'): 3.1,\n",
              " ('archbishop', 'bishop'): 7.05,\n",
              " ('letter', 'paragraph'): 4.0,\n",
              " ('page', 'paragraph'): 3.03,\n",
              " ('steeple', 'chapel'): 7.08,\n",
              " ('muscle', 'bone'): 3.65,\n",
              " ('muscle', 'tongue'): 5.0,\n",
              " ('boy', 'soldier'): 2.15,\n",
              " ('belly', 'abdomen'): 8.13,\n",
              " ('guy', 'girl'): 3.33,\n",
              " ('bed', 'chair'): 3.5,\n",
              " ('clothes', 'jacket'): 5.15,\n",
              " ('gun', 'knife'): 3.65,\n",
              " ('tin', 'metal'): 5.63,\n",
              " ('bottle', 'container'): 7.93,\n",
              " ('hen', 'turkey'): 6.13,\n",
              " ('meat', 'bread'): 1.67,\n",
              " ('arm', 'bone'): 3.83,\n",
              " ('neck', 'spine'): 5.32,\n",
              " ('apple', 'lemon'): 4.05,\n",
              " ('agony', 'grief'): 7.63,\n",
              " ('assignment', 'task'): 8.7,\n",
              " ('night', 'dawn'): 2.95,\n",
              " ('dinner', 'soup'): 3.72,\n",
              " ('calf', 'bull'): 4.93,\n",
              " ('snow', 'storm'): 4.8,\n",
              " ('nail', 'hand'): 3.42,\n",
              " ('dog', 'horse'): 2.38,\n",
              " ('arm', 'neck'): 1.58,\n",
              " ('ball', 'glove'): 1.75,\n",
              " ('flu', 'fever'): 6.08,\n",
              " ('fee', 'salary'): 3.72,\n",
              " ('nerve', 'brain'): 3.88,\n",
              " ('beast', 'animal'): 7.83,\n",
              " ('dinner', 'chicken'): 2.85,\n",
              " ('girl', 'maid'): 2.93,\n",
              " ('child', 'boy'): 5.75,\n",
              " ('alcohol', 'wine'): 7.42,\n",
              " ('nose', 'mouth'): 3.73,\n",
              " ('street', 'car'): 2.38,\n",
              " ('bell', 'door'): 2.2,\n",
              " ('box', 'hat'): 1.3,\n",
              " ('belief', 'impression'): 5.95,\n",
              " ('bias', 'opinion'): 5.6,\n",
              " ('attention', 'awareness'): 8.73,\n",
              " ('anger', 'mood'): 4.1,\n",
              " ('elegance', 'style'): 5.72,\n",
              " ('beauty', 'age'): 1.58,\n",
              " ('book', 'theme'): 2.58,\n",
              " ('friend', 'mother'): 2.53,\n",
              " ('vitamin', 'iron'): 5.55,\n",
              " ('car', 'factory'): 2.75,\n",
              " ('pact', 'condition'): 2.45,\n",
              " ('chapter', 'choice'): 0.48,\n",
              " ('arithmetic', 'rhythm'): 2.35,\n",
              " ('winner', 'presence'): 1.08,\n",
              " ('belief', 'flower'): 0.4,\n",
              " ('winner', 'goal'): 3.23,\n",
              " ('trick', 'size'): 0.48,\n",
              " ('choice', 'vein'): 0.98,\n",
              " ('hymn', 'conquest'): 0.68,\n",
              " ('endurance', 'band'): 0.4,\n",
              " ('jail', 'choice'): 1.08,\n",
              " ('condition', 'boy'): 0.48,\n",
              " ('flower', 'endurance'): 0.4,\n",
              " ('hole', 'agreement'): 0.3,\n",
              " ('doctor', 'temper'): 0.48,\n",
              " ('fraternity', 'door'): 0.68,\n",
              " ('task', 'woman'): 0.68,\n",
              " ('fraternity', 'baseball'): 0.88,\n",
              " ('cent', 'size'): 0.4,\n",
              " ('presence', 'door'): 0.48,\n",
              " ('mouse', 'management'): 0.48,\n",
              " ('task', 'highway'): 0.48,\n",
              " ('liquor', 'century'): 0.4,\n",
              " ('task', 'straw'): 0.68,\n",
              " ('island', 'task'): 0.3,\n",
              " ('night', 'chapter'): 0.48,\n",
              " ('pollution', 'president'): 0.68,\n",
              " ('gun', 'trick'): 0.48,\n",
              " ('bath', 'trick'): 0.58,\n",
              " ('diet', 'apple'): 1.18,\n",
              " ('cent', 'wife'): 0.58,\n",
              " ('chapter', 'tail'): 0.3,\n",
              " ('course', 'stomach'): 0.58,\n",
              " ('hymn', 'straw'): 0.4,\n",
              " ('dentist', 'colonel'): 0.4,\n",
              " ('wife', 'straw'): 0.4,\n",
              " ('hole', 'wife'): 0.68,\n",
              " ('pupil', 'president'): 0.78,\n",
              " ('bath', 'wife'): 0.48,\n",
              " ('people', 'cent'): 0.48,\n",
              " ('formula', 'log'): 1.77,\n",
              " ('woman', 'fur'): 0.58,\n",
              " ('apple', 'sunshine'): 0.58,\n",
              " ('gun', 'dawn'): 1.18,\n",
              " ('meal', 'waist'): 0.98,\n",
              " ('camera', 'president'): 0.48,\n",
              " ('liquor', 'band'): 0.68,\n",
              " ('stomach', 'vein'): 2.35,\n",
              " ('gun', 'fur'): 0.3,\n",
              " ('couch', 'baseball'): 0.88,\n",
              " ('worker', 'camera'): 0.68,\n",
              " ('deck', 'mouse'): 0.48,\n",
              " ('rice', 'boy'): 0.4,\n",
              " ('people', 'gun'): 0.68,\n",
              " ('cliff', 'tail'): 0.3,\n",
              " ('ankle', 'window'): 0.3,\n",
              " ('princess', 'island'): 0.3,\n",
              " ('container', 'mouse'): 0.3,\n",
              " ('wagon', 'container'): 2.65,\n",
              " ('people', 'balloon'): 0.48,\n",
              " ('dollar', 'people'): 0.4,\n",
              " ('bath', 'balloon'): 0.4,\n",
              " ('stomach', 'bedroom'): 0.4,\n",
              " ('bicycle', 'bedroom'): 0.4,\n",
              " ('log', 'bath'): 0.4,\n",
              " ('bowl', 'tail'): 0.48,\n",
              " ('go', 'come'): 2.42,\n",
              " ('take', 'steal'): 6.18,\n",
              " ('listen', 'hear'): 8.17,\n",
              " ('think', 'rationalize'): 8.25,\n",
              " ('occur', 'happen'): 9.32,\n",
              " ('vanish', 'disappear'): 9.8,\n",
              " ('multiply', 'divide'): 1.75,\n",
              " ('plead', 'beg'): 9.08,\n",
              " ('begin', 'originate'): 8.2,\n",
              " ('protect', 'defend'): 9.13,\n",
              " ('kill', 'destroy'): 5.9,\n",
              " ('create', 'make'): 8.72,\n",
              " ('accept', 'reject'): 0.83,\n",
              " ('ignore', 'avoid'): 6.87,\n",
              " ('carry', 'bring'): 5.8,\n",
              " ('leave', 'enter'): 0.95,\n",
              " ('choose', 'elect'): 7.62,\n",
              " ('lose', 'fail'): 7.33,\n",
              " ('encourage', 'discourage'): 1.58,\n",
              " ('achieve', 'accomplish'): 8.57,\n",
              " ('make', 'construct'): 8.33,\n",
              " ('listen', 'obey'): 4.93,\n",
              " ('inform', 'notify'): 9.25,\n",
              " ('receive', 'give'): 1.47,\n",
              " ('borrow', 'beg'): 2.62,\n",
              " ('take', 'obtain'): 7.1,\n",
              " ('advise', 'recommend'): 8.1,\n",
              " ('imitate', 'portray'): 6.75,\n",
              " ('win', 'succeed'): 7.9,\n",
              " ('think', 'decide'): 5.13,\n",
              " ('greet', 'meet'): 6.17,\n",
              " ('agree', 'argue'): 0.77,\n",
              " ('enjoy', 'entertain'): 5.92,\n",
              " ('destroy', 'make'): 1.6,\n",
              " ('save', 'protect'): 6.58,\n",
              " ('give', 'lend'): 7.22,\n",
              " ('understand', 'know'): 7.47,\n",
              " ('take', 'receive'): 5.08,\n",
              " ('accept', 'acknowledge'): 6.88,\n",
              " ('decide', 'choose'): 8.87,\n",
              " ('accept', 'believe'): 6.75,\n",
              " ('keep', 'possess'): 8.27,\n",
              " ('roam', 'wander'): 8.83,\n",
              " ('succeed', 'fail'): 0.83,\n",
              " ('spend', 'save'): 0.55,\n",
              " ('leave', 'go'): 7.63,\n",
              " ('come', 'attend'): 8.1,\n",
              " ('know', 'believe'): 5.5,\n",
              " ('gather', 'meet'): 7.3,\n",
              " ('make', 'earn'): 7.62,\n",
              " ('forget', 'ignore'): 3.07,\n",
              " ('multiply', 'add'): 2.7,\n",
              " ('shrink', 'grow'): 0.23,\n",
              " ('arrive', 'leave'): 1.33,\n",
              " ('succeed', 'try'): 3.98,\n",
              " ('accept', 'deny'): 1.75,\n",
              " ('arrive', 'come'): 7.05,\n",
              " ('agree', 'differ'): 1.05,\n",
              " ('send', 'receive'): 1.08,\n",
              " ('win', 'dominate'): 5.68,\n",
              " ('add', 'divide'): 2.3,\n",
              " ('kill', 'choke'): 4.92,\n",
              " ('acquire', 'get'): 8.82,\n",
              " ('participate', 'join'): 7.7,\n",
              " ('leave', 'remain'): 2.53,\n",
              " ('go', 'enter'): 4.0,\n",
              " ('take', 'carry'): 5.23,\n",
              " ('forget', 'learn'): 1.18,\n",
              " ('appoint', 'elect'): 8.17,\n",
              " ('engage', 'marry'): 5.43,\n",
              " ('ask', 'pray'): 3.72,\n",
              " ('go', 'send'): 3.75,\n",
              " ('take', 'deliver'): 4.37,\n",
              " ('speak', 'hear'): 3.02,\n",
              " ('analyze', 'evaluate'): 8.03,\n",
              " ('argue', 'rationalize'): 4.2,\n",
              " ('lose', 'keep'): 1.05,\n",
              " ('compare', 'analyze'): 8.1,\n",
              " ('disorganize', 'organize'): 1.45,\n",
              " ('go', 'allow'): 3.62,\n",
              " ('take', 'possess'): 7.2,\n",
              " ('learn', 'listen'): 3.88,\n",
              " ('destroy', 'construct'): 0.92,\n",
              " ('create', 'build'): 8.48,\n",
              " ('steal', 'buy'): 1.13,\n",
              " ('kill', 'hang'): 4.45,\n",
              " ('forget', 'know'): 0.92,\n",
              " ('create', 'imagine'): 5.13,\n",
              " ('do', 'happen'): 4.23,\n",
              " ('win', 'accomplish'): 7.85,\n",
              " ('give', 'deny'): 1.43,\n",
              " ('deserve', 'earn'): 5.8,\n",
              " ('get', 'put'): 1.98,\n",
              " ('locate', 'find'): 8.73,\n",
              " ('appear', 'attend'): 6.28,\n",
              " ('know', 'comprehend'): 7.63,\n",
              " ('pretend', 'imagine'): 8.47,\n",
              " ('satisfy', 'please'): 7.67,\n",
              " ('cherish', 'keep'): 4.85,\n",
              " ('argue', 'differ'): 5.15,\n",
              " ('overcome', 'dominate'): 6.25,\n",
              " ('behave', 'obey'): 7.3,\n",
              " ('cooperate', 'participate'): 6.43,\n",
              " ('achieve', 'try'): 4.42,\n",
              " ('fail', 'discourage'): 3.33,\n",
              " ('begin', 'quit'): 1.28,\n",
              " ('say', 'participate'): 3.82,\n",
              " ('come', 'bring'): 2.42,\n",
              " ('declare', 'announce'): 9.08,\n",
              " ('read', 'comprehend'): 4.7,\n",
              " ('take', 'leave'): 2.47,\n",
              " ('proclaim', 'announce'): 8.18,\n",
              " ('acquire', 'obtain'): 8.57,\n",
              " ('conclude', 'decide'): 7.75,\n",
              " ('please', 'plead'): 2.98,\n",
              " ('argue', 'prove'): 4.83,\n",
              " ('ask', 'plead'): 6.47,\n",
              " ('find', 'disappear'): 0.77,\n",
              " ('inspect', 'examine'): 8.75,\n",
              " ('verify', 'justify'): 4.08,\n",
              " ('assume', 'predict'): 4.85,\n",
              " ('learn', 'evaluate'): 4.17,\n",
              " ('argue', 'justify'): 5.0,\n",
              " ('make', 'become'): 4.77,\n",
              " ('discover', 'originate'): 4.83,\n",
              " ('achieve', 'succeed'): 7.5,\n",
              " ('give', 'put'): 3.65,\n",
              " ('understand', 'listen'): 4.68,\n",
              " ('expand', 'grow'): 8.27,\n",
              " ('borrow', 'sell'): 1.73,\n",
              " ('keep', 'protect'): 5.4,\n",
              " ('explain', 'prove'): 4.1,\n",
              " ('assume', 'pretend'): 3.72,\n",
              " ('agree', 'please'): 4.13,\n",
              " ('forgive', 'forget'): 3.92,\n",
              " ('clarify', 'explain'): 8.33,\n",
              " ('understand', 'forgive'): 4.87,\n",
              " ('remind', 'forget'): 0.87,\n",
              " ('get', 'remain'): 1.6,\n",
              " ('realize', 'discover'): 7.47,\n",
              " ('require', 'inquire'): 1.82,\n",
              " ('ignore', 'ask'): 1.07,\n",
              " ('think', 'inquire'): 4.77,\n",
              " ('reject', 'avoid'): 4.78,\n",
              " ('argue', 'persuade'): 6.23,\n",
              " ('pursue', 'persuade'): 3.17,\n",
              " ('accept', 'forgive'): 3.73,\n",
              " ('do', 'quit'): 1.17,\n",
              " ('investigate', 'examine'): 8.1,\n",
              " ('discuss', 'explain'): 6.67,\n",
              " ('owe', 'lend'): 2.32,\n",
              " ('explore', 'discover'): 8.48,\n",
              " ('complain', 'argue'): 4.8,\n",
              " ('withdraw', 'reject'): 6.38,\n",
              " ('keep', 'borrow'): 2.25,\n",
              " ('beg', 'ask'): 6.0,\n",
              " ('arrange', 'organize'): 8.27,\n",
              " ('reduce', 'shrink'): 8.02,\n",
              " ('speak', 'acknowledge'): 4.67,\n",
              " ('give', 'borrow'): 2.22,\n",
              " ('kill', 'defend'): 2.63,\n",
              " ('disappear', 'shrink'): 5.8,\n",
              " ('deliver', 'carry'): 3.88,\n",
              " ('breathe', 'choke'): 1.37,\n",
              " ('acknowledge', 'notify'): 5.3,\n",
              " ('become', 'seem'): 2.63,\n",
              " ('pretend', 'seem'): 4.68,\n",
              " ('accomplish', 'become'): 4.0,\n",
              " ('contemplate', 'think'): 8.82,\n",
              " ('determine', 'predict'): 5.8,\n",
              " ('please', 'entertain'): 5.0,\n",
              " ('remain', 'retain'): 5.75,\n",
              " ('pretend', 'portray'): 7.03,\n",
              " ('forget', 'retain'): 0.63,\n",
              " ('want', 'choose'): 4.78,\n",
              " ('lose', 'get'): 0.77,\n",
              " ('try', 'think'): 2.62,\n",
              " ('become', 'appear'): 4.77,\n",
              " ('leave', 'ignore'): 4.42,\n",
              " ('accept', 'recommend'): 2.75,\n",
              " ('leave', 'wander'): 3.57,\n",
              " ('keep', 'give'): 1.05,\n",
              " ('give', 'allow'): 5.15,\n",
              " ('bring', 'send'): 2.97,\n",
              " ('absorb', 'learn'): 5.48,\n",
              " ('acquire', 'find'): 6.38,\n",
              " ('leave', 'appear'): 0.97,\n",
              " ('create', 'destroy'): 0.63,\n",
              " ('begin', 'go'): 7.42,\n",
              " ('get', 'buy'): 5.08,\n",
              " ('collect', 'save'): 6.67,\n",
              " ('replace', 'restore'): 5.73,\n",
              " ('join', 'add'): 8.1,\n",
              " ('join', 'marry'): 5.35,\n",
              " ('accept', 'deliver'): 1.58,\n",
              " ('attach', 'join'): 7.75,\n",
              " ('put', 'hang'): 3.0,\n",
              " ('go', 'sell'): 0.97,\n",
              " ('communicate', 'pray'): 3.55,\n",
              " ('give', 'steal'): 0.5,\n",
              " ('add', 'build'): 4.92,\n",
              " ('bring', 'restore'): 2.62,\n",
              " ('comprehend', 'satisfy'): 2.55,\n",
              " ('portray', 'decide'): 1.18,\n",
              " ('organize', 'become'): 1.77,\n",
              " ('give', 'know'): 0.88,\n",
              " ('say', 'verify'): 4.9,\n",
              " ('cooperate', 'join'): 5.18,\n",
              " ('arrange', 'require'): 0.98,\n",
              " ('borrow', 'want'): 1.77,\n",
              " ('investigate', 'pursue'): 7.15,\n",
              " ('ignore', 'explore'): 0.4,\n",
              " ('bring', 'complain'): 0.98,\n",
              " ('enter', 'owe'): 0.68,\n",
              " ('portray', 'notify'): 0.78,\n",
              " ('remind', 'sell'): 0.4,\n",
              " ('absorb', 'possess'): 5.0,\n",
              " ('join', 'acquire'): 2.85,\n",
              " ('send', 'attend'): 1.67,\n",
              " ('gather', 'attend'): 4.8,\n",
              " ('absorb', 'withdraw'): 2.97,\n",
              " ('attend', 'arrive'): 6.08}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "simplex_pairs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_words_similarity(model, word_pair2score, print_warning=True):\n",
        "  all_pairs = {}\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "    system_similarity = model.similarity(w1, w2)\n",
        "\n",
        "    all_pairs[tuple((w1, w2))] = system_similarity\n",
        "\n",
        "  return all_pairs"
      ],
      "metadata": {
        "id": "QSNOaqR4olr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mySenses2score = compute_words_similarity(model_word2vec_text.wv, simplex_pairs)\n",
        "\n",
        "# generate_resulting_file(mySenses2score, 'non_semantic.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccbNFrpHrAlm",
        "outputId": "6b3c1b34-cbf7-45b3-dfee-4148e9412ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING (do and happen) are not present in the embedding model!!\n",
            "WARNING (do and quit) are not present in the embedding model!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic SimLex999"
      ],
      "metadata": {
        "id": "mMS4CL4TjKzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##IMPLEMENT THIS TO LOAD sense2score\n",
        "# the returned dictionary should be similar to previous word_pair2score but instead of words we consider the senses from the dataset associated with this words\n",
        "def load_semantic_simplex(path):\n",
        "  senses2score = dict()\n",
        "  word2senses = dict()\n",
        "\n",
        "  with open(path) as fr:\n",
        "    # print(fr)\n",
        "    next(fr)\n",
        "    for line in fr:\n",
        "      # print(line)\n",
        "      chunks = line.strip().split()\n",
        "      w1 = chunks[0]\n",
        "      w2 = chunks[1]\n",
        "      sim_lex_score = chunks[3]\n",
        "\n",
        "      word_w1 = chunks[0]\n",
        "      word_w2 = chunks[1]\n",
        "\n",
        "      senses_w1 = chunks[10].split(\",\")\n",
        "      senses_w2 = chunks[11].split(\",\")\n",
        "\n",
        "      word_id_pair = [word_w1, word_w2]\n",
        "      word2senses[tuple(word_id_pair)] = []\n",
        "\n",
        "      for sense_w1 in senses_w1:\n",
        "        for sense_w2 in senses_w2:\n",
        "\n",
        "          id_pair = [sense_w1, sense_w2]\n",
        "          senses2score[tuple(id_pair)] = float(sim_lex_score)\n",
        "\n",
        "          word2senses[tuple(word_id_pair)].append(tuple(id_pair))\n",
        "\n",
        "  return senses2score, word2senses"
      ],
      "metadata": {
        "id": "sacAwayhjOV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity_for_senses(model, word_pair2score, print_warning=True):\n",
        "  all_pairs = {}\n",
        "  count = 0\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    # if idx < 5:\n",
        "    #   print(idx, w1, w2, score)\n",
        "\n",
        "    # if idx == 5:\n",
        "    #   return\n",
        "\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "\n",
        "    system_similarity = model.similarity(w1, w2)\n",
        "    id_pair = [w1, w2]\n",
        "    all_pairs[tuple(id_pair)] = float(system_similarity)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  return all_pairs"
      ],
      "metadata": {
        "id": "16sX3129l76x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_pair_with_best_sense(word2senses, sense2score):\n",
        "  word2score = {}\n",
        "  for word_pair_idx, (key_word_pair, sense_pairs) in enumerate(word2senses.items()):\n",
        "    for sense_pair in sense_pairs:\n",
        "\n",
        "      maximum = 0\n",
        "\n",
        "      #check if the pair is not present in my model\n",
        "      if sense_pair not in sense2score:\n",
        "        continue\n",
        "\n",
        "      #equivalent to maximum = max(maximum, sense2score[sense_pair])\n",
        "      if sense2score[sense_pair] > maximum:\n",
        "        maximum = sense2score[sense_pair]\n",
        "\n",
        "    word2score[key_word_pair] = maximum\n",
        "\n",
        "  return word2score"
      ],
      "metadata": {
        "id": "rtuyb7u-XGCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sense2score, word2senses = load_semantic_simplex(simlex_path)\n",
        "mySenses2score = compute_similarity_for_senses(model_word2vec_sense.wv, sense2score)\n",
        "wordSenses2score = get_word_pair_with_best_sense(word2senses, mySenses2score)\n",
        "\n",
        "# print(sense2score)\n",
        "# print(word2senses)"
      ],
      "metadata": {
        "id": "9F03p34bmAtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_resulting_file(wordSenses2score)"
      ],
      "metadata": {
        "id": "Uy8S3XlFnNCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIBcdUPryoIK"
      },
      "source": [
        "### Correlation definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxeRWj3uGzO1"
      },
      "outputs": [],
      "source": [
        "def compute_correlation_score(model, word_pair2score, print_warning=True):\n",
        "  human_scores = []\n",
        "  system_scores = []\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      system_scores.append(-1) #why penalize words not present in vocabulary??\n",
        "      human_scores.append(score)\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "    system_similarity = model.similarity(w1, w2)\n",
        "    human_scores.append(score)\n",
        "    system_scores.append(system_similarity)\n",
        "\n",
        "\n",
        "  human_scores = np.array(human_scores)\n",
        "  system_scores = np.array(system_scores)\n",
        "\n",
        "  # print(f'human_scores: {human_scores}, system_scores: {system_scores}')\n",
        "  pearson_r, _ = scipy.stats.pearsonr(human_scores, system_scores)    # Pearson's r\n",
        "  spearman_rho = scipy.stats.spearmanr(human_scores, system_scores).statistic   # Spearman's rho\n",
        "  return pearson_r, spearman_rho\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here i test all my senses with all semantic simlex senses\n",
        "\n",
        "def compute_correlation_score_all_sense(model, word_pair2score, print_warning=True):\n",
        "  human_scores = []\n",
        "  system_scores = []\n",
        "  count = 0\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    # if idx < 5:\n",
        "    #   print(idx, w1, w2, score)\n",
        "\n",
        "    # if idx == 5:\n",
        "    #   return\n",
        "\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      system_scores.append(-1) #why penalize words not present in vocabulary??\n",
        "      human_scores.append(score)\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "\n",
        "    system_similarity = model.similarity(w1, w2)\n",
        "    human_scores.append(score)\n",
        "    system_scores.append(system_similarity)\n",
        "    count += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  human_scores = np.array(human_scores)\n",
        "  system_scores = np.array(system_scores)\n",
        "\n",
        "  # print(f'human_scores: {human_scores}, system_scores: {system_scores}')\n",
        "  pearson_r, _ = scipy.stats.pearsonr(human_scores, system_scores)    # Pearson's r\n",
        "  spearman_rho = scipy.stats.spearmanr(human_scores, system_scores).statistic   # Spearman's rho\n",
        "  return pearson_r, spearman_rho, count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BbN-jIJAjYvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here i test with the original word pair after i have selected the best similarity for each pair of senses\n",
        "\n",
        "def compute_correlation_score_word_senses(model, word_pair2score, print_warning=True):\n",
        "  human_scores = []\n",
        "  system_scores = []\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    if tuple((w1,w2)) not in model:\n",
        "      system_scores.append(-1) #why penalize words not present in vocabulary??\n",
        "      human_scores.append(score)\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "    system_similarity = model[tuple((w1, w2))]\n",
        "    human_scores.append(score)\n",
        "    system_scores.append(system_similarity)\n",
        "\n",
        "\n",
        "  human_scores = np.array(human_scores)\n",
        "  system_scores = np.array(system_scores)\n",
        "\n",
        "  # print(f'human_scores: {human_scores}, system_scores: {system_scores}')\n",
        "  pearson_r, _ = scipy.stats.pearsonr(human_scores, system_scores)    # Pearson's r\n",
        "  spearman_rho = scipy.stats.spearmanr(human_scores, system_scores).statistic   # Spearman's rho\n",
        "  return pearson_r, spearman_rho\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ybbUYr2QlQz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlations computation"
      ],
      "metadata": {
        "id": "b2lLMKy3kymP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_correlation_score(model_word2vec_text.wv, simplex_pairs, print_warning=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfYpj6P-kZtz",
        "outputId": "76ec854c-9a1e-4fdb-d29b-d2686cde33eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.432205471906384, 0.4459152867355886)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_correlation_score_all_sense(model_word2vec_sense.wv, sense2score, print_warning=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE35IOlokbYn",
        "outputId": "0e2140d7-5373-423c-ccfb-1d961d8c8d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.3337758484053419, 0.33123794809017093, 1258)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_correlation_score_word_senses(wordSenses2score, simplex_pairs, print_warning=False))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRBBC-orlFY6",
        "outputId": "6682178f-cb4b-4ab2-826f-7bcd6447fe6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.3524010908365524, 0.34227135455934915)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explicit Representation**"
      ],
      "metadata": {
        "id": "6K46doczBtKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute similarity"
      ],
      "metadata": {
        "id": "Bi4Wl71PLpXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texts"
      ],
      "metadata": {
        "id": "JoHJNB1gMO8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity_sparse(d_copied, w1, w2, print_warning = True):\n",
        "  if (w1 not in d_copied) or (w2 not in d_copied):\n",
        "    print(\"words not presents\")\n",
        "    return 0\n",
        "\n",
        "  key1 = set(d_copied[w1].keys())\n",
        "  key2 = set(d_copied[w2].keys())\n",
        "\n",
        "  intersection = key1.intersection(key2)\n",
        "\n",
        "  vec1 = np.array([d_copied[w1][key] for key in intersection])\n",
        "  vec2 = np.array([d_copied[w2][key] for key in intersection])\n",
        "\n",
        "  norm1 = np.linalg.norm(vec1)\n",
        "  norm2 = np.linalg.norm(vec2)\n",
        "\n",
        "  if (norm1 == 0 or norm2 == 0):\n",
        "    # print(f'norm1: {norm1}, norm2: {norm2}')\n",
        "    # print(f'v1: {vec1}, v2: {vec2}')\n",
        "    # print(w1,w2)\n",
        "    if print_warning:\n",
        "      print(f\"norms equal 0, w1: {w1}, w2: {w2}, norm1: {norm1}, norm2: {norm2}, vec1: {vec1}, vec2:{vec2}\")\n",
        "    return 0\n",
        "\n",
        "  cos_sim = np.dot(vec1, vec2.T) / (norm1 * norm2)\n",
        "  return cos_sim"
      ],
      "metadata": {
        "id": "I6rFQJDmLrvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Senses"
      ],
      "metadata": {
        "id": "2QGWKdOQMSCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity_for_senses_explicit(model, word_pair2score, print_warning=True):\n",
        "  all_pairs = {}\n",
        "  count = 0\n",
        "  for idx, ((w1, w2), score) in enumerate(word_pair2score.items()):\n",
        "    # if idx < 5:\n",
        "    #   print(idx, w1, w2, score)\n",
        "\n",
        "    # if idx == 5:\n",
        "    #   return\n",
        "\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "\n",
        "    system_similarity = compute_similarity_sparse(model, w1, w2)\n",
        "    id_pair = [w1, w2]\n",
        "    all_pairs[tuple(id_pair)] = float(system_similarity)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  return all_pairs"
      ],
      "metadata": {
        "id": "7fpQupaIMVYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_pair_with_best_sense(word2senses, sense2score):\n",
        "  word2score = {}\n",
        "  for word_pair_idx, (key_word_pair, sense_pairs) in enumerate(word2senses.items()):\n",
        "    for sense_pair in sense_pairs:\n",
        "\n",
        "      maximum = 0\n",
        "\n",
        "      #check if the pair is not present in my model\n",
        "      if sense_pair not in sense2score:\n",
        "        continue\n",
        "\n",
        "      #equivalent to maximum = max(maximum, sense2score[sense_pair])\n",
        "      if sense2score[sense_pair] > maximum:\n",
        "        maximum = sense2score[sense_pair]\n",
        "\n",
        "    word2score[key_word_pair] = maximum\n",
        "\n",
        "  return word2score"
      ],
      "metadata": {
        "id": "S9iu-sDTMe9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Texts with only words"
      ],
      "metadata": {
        "id": "lB7oQ8o1neHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante con dizionari e intersezioni keys\n",
        "\n",
        "v = text_vocabulary #set 100\n",
        "d_global_word = {elem: {} for elem in tqdm(v, leave=True, position = 0)}\n",
        "# text = sense_texts\n",
        "window_size = 2\n",
        "\n",
        "for text in tqdm(homeworks_text[:10], leave=True, position = 0):\n",
        "\n",
        "  for i, token in enumerate(text):\n",
        "    token #elem = 60th\n",
        "\n",
        "    idx_from = i - window_size if i - window_size > 0 else 0\n",
        "    idx_to = i + window_size\n",
        "\n",
        "    sliced = text[idx_from : idx_to]\n",
        "\n",
        "    # print(f'idx_from : {idx_from}, idx_to: {idx_to}, sliced: {sliced}')\n",
        "    # print(f'idx_from : {idx_from}, idx_to: {idx_to}, sliced: {sliced}, token: {token}')\n",
        "    for elem in sliced:\n",
        "      if elem == token:\n",
        "        continue\n",
        "\n",
        "      word_idx = text_vocabulary.index(elem)\n",
        "\n",
        "      if word_idx in d_global_word[token]:\n",
        "        d_global_word[token][word_idx] += 1\n",
        "      else:\n",
        "        d_global_word[token][word_idx] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEseH0JmKwgh",
        "outputId": "fbbb1919-86dd-40b6-adb3-5d95947aefcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 284044/284044 [00:00<00:00, 759454.97it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 121.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "\n",
        "# # Save to a JSON file\n",
        "# with open('explicit_word3.json', 'w') as json_file:\n",
        "#     json.dump(d_global_word, json_file)"
      ],
      "metadata": {
        "id": "mTeV6AZMK936"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Texts with senses"
      ],
      "metadata": {
        "id": "nPcEJsIEnioU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante con dizionari e intersezioni keys\n",
        "\n",
        "v = sense_vocabulary #set 100\n",
        "d_global = {elem: {} for elem in tqdm(v, leave=True, position = 0)}\n",
        "# text = sense_texts\n",
        "window_size = 2\n",
        "\n",
        "for text in tqdm(sense_texts_def[300000:400000], leave=True, position = 0):\n",
        "\n",
        "  for i, token in enumerate(text):\n",
        "    token #elem = 60th\n",
        "\n",
        "    idx_from = i - window_size if i - window_size > 0 else 0\n",
        "    idx_to = i + window_size\n",
        "\n",
        "    sliced = text[idx_from : idx_to]\n",
        "\n",
        "    # print(f'idx_from : {idx_from}, idx_to: {idx_to}, sliced: {sliced}')\n",
        "    # print(f'idx_from : {idx_from}, idx_to: {idx_to}, sliced: {sliced}, token: {token}')\n",
        "    for elem in sliced:\n",
        "      if elem == token:\n",
        "        continue\n",
        "\n",
        "      word_idx = sense_vocabulary.index(elem)\n",
        "\n",
        "      if word_idx in d_global[token]:\n",
        "        d_global[token][word_idx] += 1\n",
        "      else:\n",
        "        d_global[token][word_idx] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdjnAC844QgQ",
        "outputId": "0e305bf6-24c9-4b6d-f1b9-68d2334540cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 289408/289408 [00:00<00:00, 1417713.97it/s]\n",
            "100%|██████████| 100000/100000 [17:07<00:00, 97.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "\n",
        "# # Save to a JSON file\n",
        "# with open('explicit4.json', 'w') as json_file:\n",
        "#     json.dump(d_global, json_file)"
      ],
      "metadata": {
        "id": "G5jhZPkF7Jk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for key, value in d_global.items():\n",
        "\n",
        "#   print(f'key: {key} --- d_global[key]: {d_global[key]}')\n",
        "\n",
        "\n",
        "\n",
        "#from dictionary transform to array\n",
        "\n",
        "# d_copied = dict()\n",
        "\n",
        "# for key, value in tqdm(d_global.items(), leave=True, position = 0):\n",
        "#   d_copied[key] = np.array([value[idx_v] for idx_v in sense_vocabulary])\n",
        "\n",
        "#print the array version\n",
        "\n",
        "# for key, value in d_copied.items():\n",
        "#   print(f'key: {key} --- d_copied[key]: {d_copied[key]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8uPVI1Fi0MZ",
        "outputId": "affc6f56-9842-4277-b349-8db570cca2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7225/7225 [00:12<00:00, 594.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation definitions"
      ],
      "metadata": {
        "id": "Wk9hcWftLv9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_correlation_score_explicit_text(model, word_pair2score, print_warning=False):\n",
        "  human_scores = []\n",
        "  system_scores = []\n",
        "  for (w1, w2), score in word_pair2score.items():\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      system_scores.append(-1) #why penalize words not present in vocabulary??\n",
        "      human_scores.append(score)\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "    system_similarity = compute_similarity_sparse(model,w1, w2)\n",
        "    human_scores.append(score)\n",
        "    system_scores.append(system_similarity)\n",
        "  human_scores = np.array(human_scores)\n",
        "  system_scores = np.array(system_scores)\n",
        "\n",
        "  # print(f'human_scores: {human_scores}, system_scores: {system_scores}')\n",
        "  pearson_r, _ = scipy.stats.pearsonr(human_scores, system_scores)    # Pearson's r\n",
        "  spearman_rho = scipy.stats.spearmanr(human_scores, system_scores).statistic   # Spearman's rho\n",
        "  return pearson_r, spearman_rho\n"
      ],
      "metadata": {
        "id": "TCxH00zLId5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_correlation_score_explicit_sense(model, word_pair2score, print_warning=False):\n",
        "  human_scores = []\n",
        "  system_scores = []\n",
        "  for (w1, w2), score in word_pair2score.items():\n",
        "    if (w1 not in model) or (w2 not in model):\n",
        "      system_scores.append(-1) #why penalize words not present in vocabulary??\n",
        "      human_scores.append(score)\n",
        "      if print_warning:\n",
        "        print(f\"WARNING ({w1} and {w2}) are not present in the embedding model!!\" )\n",
        "      continue\n",
        "    system_similarity = compute_similarity_sparse(model,w1, w2)\n",
        "    human_scores.append(score)\n",
        "    system_scores.append(system_similarity)\n",
        "  human_scores = np.array(human_scores)\n",
        "  system_scores = np.array(system_scores)\n",
        "\n",
        "  # print(f'human_scores: {human_scores}, system_scores: {system_scores}')\n",
        "  pearson_r, _ = scipy.stats.pearsonr(human_scores, system_scores)    # Pearson's r\n",
        "  spearman_rho = scipy.stats.spearmanr(human_scores, system_scores).statistic   # Spearman's rho\n",
        "  return pearson_r, spearman_rho\n"
      ],
      "metadata": {
        "id": "jtgf22ODoKJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute correlations"
      ],
      "metadata": {
        "id": "TdK8HzFuL6VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # sense2score, word2senses = load_semantic_simplex(simlex_path)\n",
        "# mySensesExplicit2score = compute_similarity_for_senses_explicit(d_global, sense2score)\n",
        "# wordSenses2score = get_word_pair_with_best_sense(word2senses, mySensesExplicit2score)\n",
        "\n",
        "# # print(sense2score)\n",
        "# # print(word2senses)\n",
        "# wordSenses2score\n",
        "# compute_similarity_sparse(d_global, 'glass%1:27:00::', 'crystal%1:27:00::')\n",
        "# print(compute_correlation_score_word_senses(wordSenses2score, simplex_pairs, print_warning=False))"
      ],
      "metadata": {
        "id": "_zAaYv6X8cKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vB5KuTe8CYez"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oHmotf1RThrD",
        "1qKeU-EUm-l2",
        "oRj6gq6wFdLH",
        "6K46doczBtKz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}