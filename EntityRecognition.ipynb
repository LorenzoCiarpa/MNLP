{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Table-filling approach**"
      ],
      "metadata": {
        "id": "ipaoJYyXzTu3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5TXd1-PmeIF"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "Run this section to import and/or download the libraries needed for the proper functioning of the notebook and to download the dataset from source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-7FFAHRd2xz",
        "outputId": "c2629e3b-e0df-47c0-d581-2d9effa99ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp2023-hw3'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 20 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (23/23), 8.01 MiB | 11.34 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SapienzaNLP/nlp2023-hw3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGbpF_qMoVEM",
        "outputId": "0f53de4d-c6c9-4010-ed4d-72308d3f14b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece # used by huggingface\n",
        "!pip install transformers # install huggingface transformers\n",
        "!pip install -q pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UuoWrolpjZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e0acf6-0c11-40da-de5b-b093ddeb425b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 1234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1234"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#import libraries here\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Any, Dict, Union, Set, Callable\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AlbertTokenizer, AlbertModel\n",
        "\n",
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "SEED:int = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "pl.seed_everything(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcEQOEhkgM6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2c7148b7bad64cc98cae78956cdb9cbd",
            "be18b46da9b74ad18207dbbb3570cf1b",
            "924acfc43eaf4f1cbea18a78a1d3d1a5",
            "bb0b06a0114e4ed8956a7f34dd4582f5",
            "de3a2bd3a33a41e4a878f16eea06904d",
            "97e3af27da7b46dbbd8819c4473cf46d",
            "7728fa5820984b87ba37e435ca879e12",
            "e0a0b73587e64fc2b37a4705e8435d62",
            "97b5e5057088430c8e58060ee12de3d8",
            "5200823f31fd47bd9b4e0063865e81b8",
            "e1c4579450cd46fdb3b80b8a3bb83abf",
            "578fbe0dd934403a925e5c6f2cb8a316",
            "0b7bb4432d46407e801869729127ca52",
            "97fabfd06266440cadfad66212483eec",
            "6e37cfd55730441d96fa28d00de508ce",
            "a2321ffd4e1f416cbf9360b79983fb0d",
            "dd4dd7613cac4790b9701a6dd5f25bc6",
            "c9f0f6451a624c42894d46ac886f9725",
            "0162b65c629c4cffa309819371a75cd7",
            "7ae90e02b4a345e8a55f5a8b955b89a3",
            "ca466a8a39594c72991f36ef0ccb375a",
            "cb1b0c8220b64cc48b01987e7cc3df9c",
            "8f56c09776c84c449661faba77b4f50d",
            "b1924cd333934d6fbf3aed054dd283c6",
            "d0b924f3b45c49f7ad0202e69c5feda5",
            "5937191c989647cdb0dc2aa53b15f6c3",
            "1b2cf377fecb4f28be3b6c8c94c8b030",
            "023827ecf1584048a7536cd0fde1f9f2",
            "1c634a57bf0f47e78f308bc2ed45d486",
            "240cc7cf20b34f9282ef355a75450e9a",
            "29ce966bb0e44e20a712ca596bfa1dad",
            "3e043ced6d8d4c228e77ff18a50c62e6",
            "d987b24ae2ea4986b968e026a849580a",
            "08ede069bc214354bf4b07f3c459aed8",
            "e6238a600f01417a8911ca5b806e673f",
            "5bfd6ee09160459b853e0ba6a5a132bf",
            "ae84175a4f8241f184b28dfe389c1d7a",
            "53be24a991ec4889a34a7a187a759a9b",
            "53bd50c7f0d342f093c94a4cc08b5fbb",
            "87a1b1cb87984ec8a064f20fd29afd9d",
            "496c086753bc4f7d8b45d70ada95a833",
            "847605d3275a442d963438a2cb8da6fd",
            "9b9d6f6ed5114b96a7e83440a7cce64a",
            "ddd746d4118f481fbbaec8e0bc0ae7bb"
          ]
        },
        "outputId": "62c1380d-1bd8-4bcd-a475-0253a6b07cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c7148b7bad64cc98cae78956cdb9cbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "578fbe0dd934403a925e5c6f2cb8a316"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f56c09776c84c449661faba77b4f50d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08ede069bc214354bf4b07f3c459aed8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "language_model = \"distilbert-base-uncased\"\n",
        "# language_model = 'bert-base-cased'\n",
        "# language_model = 'roberta-base'\n",
        "# language_model = 'albert-base-v2'\n",
        "\n",
        "if language_model == \"distilbert-base-uncased\":\n",
        "  tokenizer = AutoTokenizer.from_pretrained(language_model)\n",
        "if language_model == 'bert-base-cased':\n",
        "  tokenizer = AutoTokenizer.from_pretrained(language_model)\n",
        "  # model_bert = AutoModel.from_pretrained(\"bert-base-cased\")\n",
        "if language_model == 'roberta-base':\n",
        "  tokenizer = AutoTokenizer.from_pretrained(language_model, add_prefix_space=True)\n",
        "if language_model == 'albert-base-v2':\n",
        "  tokenizer = AutoTokenizer.from_pretrained(language_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7EXkJ94Orgf"
      },
      "outputs": [],
      "source": [
        "#some global parameters & constants\n",
        "DATASET_DIR = \"nlp2023-hw3/data\"\n",
        "PRINT_BAR = '-' * 10\n",
        "file_type_dir = \"jsonl\"  #or \"xml\"\n",
        "\n",
        "#Not used\n",
        "BIO_TYPES = {'LOCATION', 'ORGANIZATION', 'PERSON'}\n",
        "BIO_DICT = {\n",
        "    'O': 0,\n",
        "    'B-LOCATION': 1,\n",
        "    'I-LOCATION': 2,\n",
        "    'B-ORGANIZATION': 3,\n",
        "    'I-ORGANIZATION': 4,\n",
        "    'B-PERSON': 5,\n",
        "    'I-PERSON': 6,\n",
        "    'PAD': -100\n",
        "}\n",
        "\n",
        "idx2bio = {v: k for k, v in BIO_DICT.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKBqcZTiVSmn"
      },
      "source": [
        "## Dataset Downloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlQv_0UTI42n"
      },
      "outputs": [],
      "source": [
        "def downloadDataset(dataset_prefix: str) -> List[Dict]:\n",
        "  '''\n",
        "  Download the dataset.\n",
        "  '''\n",
        "  data_path = os.path.join(DATASET_DIR, dataset_prefix)\n",
        "  data_path += '.' + file_type_dir\n",
        "\n",
        "  with open(data_path) as f:\n",
        "    sentences = f.read().splitlines()\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "      sentences[i] = json.loads(sentence)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQPhzpzgJGwK"
      },
      "outputs": [],
      "source": [
        "t_set = downloadDataset(\"train\")\n",
        "te_set = downloadDataset(\"test\")\n",
        "d_set = downloadDataset(\"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6-CdsBPN0Kr"
      },
      "outputs": [],
      "source": [
        "# print(len(t_set))\n",
        "# print(len(te_set))\n",
        "# print(len(d_set))\n",
        "# print(t_set[0])\n",
        "# print(t_set[0]['relations'][0]['subject'])\n",
        "# print(t_set[0]['relations'][0]['relation'])\n",
        "# print(t_set[0]['relations'][0]['object'])\n",
        "# print(t_set[0]['relations'][0].keys())\n",
        "# print(t_set[0].keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OgLSPvVGF70"
      },
      "source": [
        "## From dataset to dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVcIb7dwJeo9"
      },
      "outputs": [],
      "source": [
        "def downloadRelations(DATASET_DIR: str, dataset_prefix: str, file_type_dir: str) -> Tuple[Dict, Dict]:\n",
        "  '''\n",
        "  Get the relations from the relations2id.json file and create the inverse relation idx2rel.\n",
        "  '''\n",
        "  data_path = os.path.join(DATASET_DIR, dataset_prefix)\n",
        "  data_path += '.' + file_type_dir\n",
        "\n",
        "  with open(data_path) as f:\n",
        "    relations = f.read()\n",
        "    rel2idx = json.loads(relations)\n",
        "\n",
        "  idx2rel = {}\n",
        "  for key, value in rel2idx.items():\n",
        "    idx2rel[value] = key\n",
        "\n",
        "  return rel2idx, idx2rel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6QE4XK-md4h"
      },
      "outputs": [],
      "source": [
        "rel2idx, idx2rel = downloadRelations(DATASET_DIR, 'relations2id', 'json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re__-2H6mr0u"
      },
      "outputs": [],
      "source": [
        "#DEV\n",
        "\n",
        "tokens_s = []\n",
        "relations_s = []\n",
        "for i, data in enumerate(d_set):\n",
        "  tokens_s.append(data[\"tokens\"])\n",
        "  relations_s.append(data[\"relations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ6QEpYRvOWe"
      },
      "outputs": [],
      "source": [
        "#TEST\n",
        "\n",
        "test_tokens_s = []\n",
        "test_relations_s = []\n",
        "for i, data in enumerate(te_set):\n",
        "  test_tokens_s.append(data[\"tokens\"])\n",
        "  test_relations_s.append(data[\"relations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0oyaQeb2nuz"
      },
      "outputs": [],
      "source": [
        "#TRAIN\n",
        "train_tokens_s = []\n",
        "train_relations_s = []\n",
        "for i, data in enumerate(t_set):\n",
        "  train_tokens_s.append(data[\"tokens\"])\n",
        "  train_relations_s.append(data[\"relations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VMwFP2Qm2U_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d6696e-8cb8-4610-9ac8-25ae28e771a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In', 'Queens', ',', 'North', 'Shore', 'Towers', ',', 'near', 'the', 'Nassau', 'border', ',', 'supplanted', 'a', 'golf', 'course', ',', 'and', 'housing', 'replaced', 'a', 'gravel', 'quarry', 'in', 'Douglaston', '.']\n",
            "[{'subject': {'start_idx': 24, 'end_idx': 25, 'entity_type': 'LOCATION', 'text': 'Douglaston'}, 'relation': '/location/neighborhood/neighborhood_of', 'object': {'start_idx': 1, 'end_idx': 2, 'entity_type': 'LOCATION', 'text': 'Queens'}}, {'subject': {'start_idx': 1, 'end_idx': 2, 'entity_type': 'LOCATION', 'text': 'Queens'}, 'relation': '/location/location/contains', 'object': {'start_idx': 24, 'end_idx': 25, 'entity_type': 'LOCATION', 'text': 'Douglaston'}}]\n"
          ]
        }
      ],
      "source": [
        "print(tokens_s[0])\n",
        "print(relations_s[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOjNSS-8Q4PQ"
      },
      "source": [
        "## Aux Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7SOHe1wsWS1"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader):\n",
        "  all_test_losses = []\n",
        "  model.eval()\n",
        "\n",
        "  for i, batch in tqdm(enumerate(dataloader), total = len(dataloader), position = 0, leave = True):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    sentences = batch['sentences']\n",
        "    # ner_labels = batch['ner_labels']\n",
        "    re_labels = batch['table_re']\n",
        "\n",
        "    tokens = tokenizer(sentences,\n",
        "                      return_tensors=\"pt\",\n",
        "                      padding=True,\n",
        "                      is_split_into_words=True)\n",
        "\n",
        "    tokens['labels'] = re_labels\n",
        "\n",
        "    words_ids = [\n",
        "      tokens[i].word_ids\n",
        "      for i in range(len(tokens['input_ids']))\n",
        "    ]\n",
        "\n",
        "    batch = {k: v.to(hypers.device) for k, v in tokens.items()}\n",
        "    batch['compute_loss'] = True\n",
        "    batch['compute_predictions'] = True\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**batch)\n",
        "    loss = outputs[\"loss\"]\n",
        "    # loss.backward()\n",
        "    # optimizer.step()\n",
        "    all_test_losses.append(loss.item())\n",
        "    if i % 100 == 0:\n",
        "      print(f'iteration: {i}, loss: {loss.item()}')\n",
        "\n",
        "  return np.array(all_test_losses).mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1mtlrTPsSfF"
      },
      "outputs": [],
      "source": [
        "def split_answer_in_samples(indices: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]) -> Dict:\n",
        "  '''\n",
        "  Return 3 List[List[int]], where each List[int] contains the indices for teh subjects and objects belonging to that specific batch\n",
        "  batch_idxs_sample will look like:\n",
        "  [[0, 0, 0, 0],\n",
        "  [1, 1],\n",
        "  [2, 2],\n",
        "  [3, 3, 3, 3, 3, 3],\n",
        "  [4, 4, 4, 4],\n",
        "  [5, 5, 5, 5],\n",
        "  [6, 6, 6, 6, 6, 6],\n",
        "  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]]\n",
        "\n",
        "  While subjects_sample looks like :\n",
        "  [[5, 6, 7, 8],\n",
        "  [10, 11],\n",
        "  [6, 6],\n",
        "  [78, 87, 87, 87, 87, 87],\n",
        "  [12, 20, 37, 37],\n",
        "  [14, 14, 14, 14],\n",
        "  [2, 2, 2, 23, 24, 25],\n",
        "  [27, 27, 28, 28, 29, 29, 52, 52, 52, 53, 53, 53]]\n",
        "\n",
        "  '''\n",
        "  batch_idxs = indices[0]\n",
        "  subjects_idxs = indices[1]\n",
        "  objects_idxs = indices[2]\n",
        "\n",
        "  relation_pred = []\n",
        "\n",
        "  #It consider always batches with 8 samples\n",
        "  #improvement: pass batch_size as parameters\n",
        "\n",
        "  batch_idxs_sample = [[] for i in range(8)]\n",
        "  subjects_sample = [[] for i in range(8)]\n",
        "  objects_sample = [[] for i in range(8)]\n",
        "\n",
        "\n",
        "  for i, sample in enumerate(batch_idxs):\n",
        "    batch_idxs_sample[sample].append(batch_idxs[i].item())\n",
        "    subjects_sample[sample].append(subjects_idxs[i].item())\n",
        "    objects_sample[sample].append(objects_idxs[i].item())\n",
        "\n",
        "  rets = {\n",
        "      'batch_idxs_sample': batch_idxs_sample,\n",
        "      'subjects_sample': subjects_sample,\n",
        "      'objects_sample': objects_sample,\n",
        "  }\n",
        "\n",
        "  return rets\n",
        "\n",
        "def getTuples(l_subjects_batches: List[List[int]], l_objects_batches: List[List[int]]) -> Tuple[List[List[List[int]]], List[List[List[int]]]]:\n",
        "  '''\n",
        "  For each batch, return two List[List[int]] corresponding to the subjects and objects.\n",
        "  they contain all the spans relative the the subject and the object the partecipate to the same relation.\n",
        "\n",
        "  Example for subject in output:\n",
        "  [[[5, 6, 7, 8]],\n",
        "  [[10, 11]],\n",
        "  [[6, 6]],\n",
        "  [[78], [87, 87, 87, 87], [87]],\n",
        "  [[12], [20], [37], [37]],\n",
        "  [[14, 14, 14, 14]],\n",
        "  [[2, 2, 2], [23, 24, 25]],\n",
        "  [[27, 27], [28, 28], [29, 29], [52, 52, 52], [53, 53, 53]]]\n",
        "\n",
        "  Example for object in output:\n",
        "  [[[12, 12, 12, 12]],\n",
        "  [[13, 13]],\n",
        "  [[15, 16]],\n",
        "  [[87], [6, 7, 8, 9], [78]],\n",
        "  [[37], [37], [12], [20]],\n",
        "  [[8, 9, 10, 11]],\n",
        "  [[23, 24, 25], [2, 2, 2]],\n",
        "  [[52, 53], [52, 53], [52, 53], [27, 28, 29], [27, 28, 29]]]\n",
        "\n",
        "  This means that in the first sample, we have only one relation, and the token span for the subject ranges in [5,8]\n",
        "  '''\n",
        "  all_tups_subj = []\n",
        "  all_tups_obj = []\n",
        "\n",
        "  #loop over the sample in the batch, i.e. subjs = [78, 87, 87, 87, 87, 87]\n",
        "  for sample_num in range(len(l_subjects_batches)):\n",
        "    subjs = l_subjects_batches[sample_num]\n",
        "    objs = l_objects_batches[sample_num]\n",
        "\n",
        "    tups_subj = []\n",
        "    tups_obj = []\n",
        "\n",
        "    tup_sub = []\n",
        "    tup_obj = []\n",
        "\n",
        "    #loop over each relation in the sample, i.e 87\n",
        "    for i, sub, in enumerate(subjs):\n",
        "\n",
        "      #init teh emoty arraays\n",
        "      if i == 0:\n",
        "        tup_sub.append(subjs[i])\n",
        "        tup_obj.append(objs[i])\n",
        "\n",
        "      #if the new token_idx is too much greater or is smaller than the last one, it means i changed subject\n",
        "      elif (subjs[i] - subjs[i-1] > 1) or (subjs[i] - subjs[i-1] < 0):\n",
        "\n",
        "        tups_subj.append(tup_sub)\n",
        "        tups_obj.append(tup_obj)\n",
        "\n",
        "        tup_sub = [subjs[i]]\n",
        "        tup_obj = [objs[i]]\n",
        "\n",
        "      #if the new token_idx is too much greater or is smaller than the last one, it means i changed object\n",
        "      elif (objs[i] - objs[i-1] > 1) or (objs[i] - objs[i-1] < 0):\n",
        "\n",
        "        tups_subj.append(tup_sub)\n",
        "        tups_obj.append(tup_obj)\n",
        "\n",
        "        tup_sub = [subjs[i]]\n",
        "        tup_obj = [objs[i]]\n",
        "\n",
        "      #it continues the same subject or object\n",
        "      else:\n",
        "        tup_sub.append(subjs[i])\n",
        "        tup_obj.append(objs[i])\n",
        "\n",
        "    tups_subj.append(tup_sub)\n",
        "    tups_obj.append(tup_obj)\n",
        "\n",
        "    all_tups_subj.append(tups_subj)\n",
        "    all_tups_obj.append(tups_obj)\n",
        "\n",
        "  return all_tups_subj, all_tups_obj\n",
        "\n",
        "def getOriginalRelations(all_tups_subjs: List[List[List[int]]], all_tups_objs: List[List[List[int]]], answers: torch.Tensor, words_ids: List[List[int]]) -> List[list[Dict]]:\n",
        "  '''\n",
        "  Given two List[List[List[int]]], return the original relation between subject and object back mapping the idx to the relation.\n",
        "  '''\n",
        "\n",
        "  all_relations = []\n",
        "  #Loop over each sample in the batch\n",
        "  for i, (tup_subjs, tups_objs) in enumerate(zip(all_tups_subjs, all_tups_objs)):\n",
        "    word_ids = words_ids[i]\n",
        "    relations = []\n",
        "\n",
        "    #Loop over a singe relation, where subj and obj are List[int] corresponding to the token spans, i.e. subj = [5,6,7,8] -> ([5,8])\n",
        "    for subj, obj in zip(tup_subjs, tups_objs):\n",
        "      #skip if they are empty\n",
        "      if not subj or not obj:\n",
        "        continue\n",
        "\n",
        "      #skip if a padding has been predicted\n",
        "      if word_ids[subj[0]] == None or word_ids[subj[-1]] == None or word_ids[obj[0]] == None or word_ids[obj[-1]] == None:\n",
        "        continue\n",
        "\n",
        "      #retrieve the token span, i.e. i.e. subj = [5,6,7,8] -> [5,9]\n",
        "      subj_start, subj_end = word_ids[subj[0]], (word_ids[subj[-1]] + 1)\n",
        "      obj_start, obj_end = word_ids[obj[0]], (word_ids[obj[-1]] + 1)\n",
        "\n",
        "      rel = {\n",
        "          'subject': {\n",
        "              'start_idx': subj_start,\n",
        "              'end_idx': subj_end,\n",
        "          },\n",
        "\n",
        "          'relation': idx2rel[answers[i][subj[0]][obj[0]].item()],\n",
        "\n",
        "          'object': {\n",
        "              'start_idx': obj_start,\n",
        "              'end_idx': obj_end,\n",
        "          }\n",
        "      }\n",
        "\n",
        "      #Avoid duplicate\n",
        "      if rel not in relations:\n",
        "        relations.append(rel)\n",
        "\n",
        "    all_relations.append(relations)\n",
        "\n",
        "  return all_relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dGG9nFhuxGd"
      },
      "outputs": [],
      "source": [
        "def getLabelsIndices(labels: torch.Tensor) -> torch.Tensor:\n",
        "  '''\n",
        "  Return the indices of all relations, so this function filters out all the padding and all 'no_relations' indices.\n",
        "  '''\n",
        "  labels_no_zero = labels != 0\n",
        "  labels_no_minus_100 = labels != -100\n",
        "  labels_index = labels_no_zero & labels_no_minus_100\n",
        "  labels_indices = torch.where(labels_index == True)\n",
        "  return labels_indices\n",
        "\n",
        "def computeRelations(indices: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], result: torch.Tensor, words_ids: List[List[int]]) -> List[List[Dict]]:\n",
        "  '''\n",
        "  Given a tuple of indices retrieve the correct subjects and objects token spans and their relative relations.\n",
        "  '''\n",
        "  l_batch_indices_batches, l_subjects_batches, l_objects_batches = split_answer_in_samples(indices).values()\n",
        "  all_tups_subjs, all_tups_objs = getTuples(l_subjects_batches, l_objects_batches)\n",
        "  all_relations_pred = getOriginalRelations(all_tups_subjs, all_tups_objs, result, words_ids)\n",
        "  return all_relations_pred\n",
        "\n",
        "def score(targets: List[List[Dict]], predictions: List[List[Dict]]) -> Tuple[float, float, float]:\n",
        "    '''\n",
        "    Compute f1, precision and recall. Taken from the Homework Repository.\n",
        "    '''\n",
        "\n",
        "    true_positives = 0\n",
        "    num_golds = 0\n",
        "    num_preds = 0\n",
        "\n",
        "    def get_tupled_labels(rel_dicts: List[Dict]) -> List[Tuple[Tuple[int, int], str, Tuple[int, int]]]:\n",
        "        tupled_labels = []\n",
        "        for rel_dict in rel_dicts:\n",
        "            subject_dict, object_dict = rel_dict[\"subject\"], rel_dict[\"object\"]\n",
        "            tupled_labels.append(\n",
        "                (\n",
        "                    (subject_dict[\"start_idx\"], subject_dict[\"end_idx\"]),\n",
        "                    rel_dict[\"relation\"],\n",
        "                    (object_dict[\"start_idx\"], object_dict[\"end_idx\"])\n",
        "                )\n",
        "            )\n",
        "        return tupled_labels\n",
        "\n",
        "    for sent_targets, sent_predictions in zip(targets, predictions):\n",
        "        sent_targets, sent_predictions = get_tupled_labels(sent_targets), get_tupled_labels(sent_predictions)\n",
        "        true_positives += len(set(sent_targets).intersection(set(sent_predictions)))\n",
        "        num_golds += len(sent_targets)\n",
        "        num_preds += len(sent_predictions)\n",
        "    precision = true_positives / num_preds if num_preds > 0 else 0.0\n",
        "    recall = true_positives / num_golds if num_golds > 0 else 0.0\n",
        "\n",
        "    f1_score = (\n",
        "        (2 * precision * recall) / (precision + recall)\n",
        "        if precision + recall > 0\n",
        "        else 0.0\n",
        "    )\n",
        "    return f1_score, precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL1pyo8jzWgc"
      },
      "source": [
        "## Collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u2zczPQXFti"
      },
      "outputs": [],
      "source": [
        "def getWordIds(tokens_batch: List[List[str]]) -> List[List[int]]:\n",
        "  '''\n",
        "  Compure the tokenization of a list of sentences and return the back mapping to the original sentences for each sample.\n",
        "  '''\n",
        "  tokenized = tokenizer(tokens_batch, return_tensors=\"pt\",\n",
        "                                    padding='longest',\n",
        "                                    is_split_into_words=True)\n",
        "  words_ids = [\n",
        "    tokenized[i].word_ids\n",
        "    for i in range(len(tokenized['input_ids']))\n",
        "  ]\n",
        "\n",
        "  return tokenized, words_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlpYI9TM4h_F"
      },
      "outputs": [],
      "source": [
        "def find_indices(arr: List[int], target: int) -> List[int]:\n",
        "    '''\n",
        "    Return a list of indices that correspond to the original word in the tokenized sentence.\n",
        "    '''\n",
        "    return [index for index, value in enumerate(arr) if value == target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsvjaZ_Izapn"
      },
      "outputs": [],
      "source": [
        "def genTrueLabels(tokenized: Dict, relations_batch: List[List[Dict]], words_ids: List[List[int]]) -> torch.Tensor:\n",
        "  '''\n",
        "  Generate the ground truths matrices for each sentence, where given a subject with span [2,4] and an object with span [5,6],\n",
        "  return a matrix where the values [2,5], [3,5] are equals to the relation label.\n",
        "  '''\n",
        "\n",
        "  all_ner = []\n",
        "  table_re = []\n",
        "\n",
        "  #loop over the batch\n",
        "  for i, (text, relations) in enumerate(zip(tokenized['input_ids'], relations_batch)):\n",
        "\n",
        "    #for each sample i create a matrix with shape (max_len X max_len) and init all the values equals -100\n",
        "    table_re_item = torch.ones( (text.shape[0], text.shape[0]) ) * -100\n",
        "\n",
        "    indexes = np.where(np.array(words_ids[i]) != None)[0]\n",
        "    rows, cols = np.ix_(indexes, indexes)\n",
        "\n",
        "    #set to 'no_relation' all the tokens that are not paddings\n",
        "    table_re_item[rows, cols] = 0\n",
        "\n",
        "    for relation in relations:\n",
        "      subj = relation['subject']\n",
        "      obj = relation['object']\n",
        "      rel = relation['relation']\n",
        "\n",
        "      subj_tokens_indices = list( range(subj['start_idx'], subj['end_idx']) )\n",
        "      obj_tokens_indices = list( range(obj['start_idx'], obj['end_idx']) )\n",
        "\n",
        "      word_ids = words_ids[i]\n",
        "\n",
        "      #given the span in the original sentence, finds the new span in the tokenized sentence\n",
        "      subj_bert_indices = []\n",
        "      for tok in subj_tokens_indices:\n",
        "        subj_bert_indices += find_indices(word_ids, tok)\n",
        "\n",
        "      obj_bert_indices = []\n",
        "      for tok in obj_tokens_indices:\n",
        "        obj_bert_indices += find_indices(word_ids, tok)\n",
        "\n",
        "      subj_bert_indices = torch.tensor(subj_bert_indices)\n",
        "      obj_bert_indices = torch.tensor(obj_bert_indices)\n",
        "\n",
        "      #set the correct relation between the subjct and object spans in the tokenized matrix\n",
        "      if len(subj_bert_indices) > len(obj_bert_indices):\n",
        "        table_re_item[subj_bert_indices[:, None], obj_bert_indices] = rel2idx[rel]\n",
        "      elif len(subj_bert_indices) < len(obj_bert_indices):\n",
        "        table_re_item[subj_bert_indices, obj_bert_indices[:, None]] = rel2idx[rel]\n",
        "      else:\n",
        "        table_re_item[subj_bert_indices, obj_bert_indices] = rel2idx[rel]\n",
        "\n",
        "    table_re.append(table_re_item)\n",
        "\n",
        "  table_re = torch.stack(table_re)\n",
        "\n",
        "  return table_re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1jig0MQJHiH"
      },
      "outputs": [],
      "source": [
        "# tokens_batch, relations_batch = tokens_s[0:2], relations_s[0:2]\n",
        "# tokenized = tokenizer(tokens_batch, return_tensors=\"pt\",\n",
        "#                                     padding='longest',\n",
        "#                                     is_split_into_words=True)\n",
        "\n",
        "# words_ids = [\n",
        "#   tokenized[i].word_ids\n",
        "#   for i in range(len(tokenized['input_ids']))\n",
        "# ]\n",
        "\n",
        "# table_re = genTrueLabels(tokenized, relations_batch, words_ids)\n",
        "\n",
        "#print for the re table\n",
        "#SAMPLE 0\n",
        "# print(table_re[0,27,2])\n",
        "# print(table_re[0,28,2])\n",
        "# print(table_re[0,2,27])\n",
        "# print(table_re[0,2,28])\n",
        "# print()\n",
        "\n",
        "# #SAMPLE 1\n",
        "# print(table_re[1,122,23])\n",
        "# print(table_re[1,123,23])\n",
        "# print()\n",
        "\n",
        "# #SAMPLE 2\n",
        "# print(table_re[2,10,7])\n",
        "# print(table_re[2,10,8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG-RvHLTEA8m"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW3KwD4wEM8T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "class DatasetRe(Dataset):\n",
        "  def __init__(self,\n",
        "               sentences,\n",
        "               relations) -> None:\n",
        "\n",
        "    self.sentences = sentences\n",
        "    self.relations = relations\n",
        "\n",
        "  ''' returns how many entries we have for a specific category '''\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.sentences)\n",
        "\n",
        "  ''' returns one item of one category '''\n",
        "  def __getitem__(self, idx:int) -> dict:\n",
        "    return self.sentences[idx], self.relations[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0gjCvJ0zHRd"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNxemck7uW5K"
      },
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "class hypers:\n",
        "    save_model = False\n",
        "    save_model_path = '/content/drive/MyDrive/AI/NLP_HW3/re_table_final_doccia.pth'\n",
        "\n",
        "    load_model = True\n",
        "\n",
        "    load_model_path = '/content/drive/MyDrive/AI/NLP_HW3/re_table_final_doccia.pth' #'/content/drive/MyDrive/AI/final_combo_re_hw3_1.pth'\n",
        "\n",
        "    embedding_dim = 768\n",
        "    input_size = 768\n",
        "    learning_rate = 1e-3\n",
        "    epochs = 5\n",
        "    batch_size = 8\n",
        "    print_step = 100\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVelRp9O-BsS"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnCdrQxa3MSv"
      },
      "source": [
        "### Wise-Product and Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWfZ82MEPQKf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class REWise(torch.nn.Module):\n",
        "    def __init__(self, language_model_name: str, num_labels: int, fine_tune_lm: bool = True, *args, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        # layers\n",
        "        self.transformer_model = AutoModel.from_pretrained(language_model_name, output_hidden_states=True, output_attentions=True)\n",
        "        if not fine_tune_lm:\n",
        "            for param in self.transformer_model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "        self.classifier = torch.nn.Linear(\n",
        "            100, num_labels, bias=False\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fcAttention1 = nn.Linear(12, 768)\n",
        "        self.fcAttentionClassifier = nn.Linear(100, num_labels, bias=False)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.transformer_model.config.hidden_size, self.transformer_model.config.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.transformer_model.config.hidden_size , 100)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor = None,\n",
        "        attention_mask: torch.Tensor = None,\n",
        "        token_type_ids: torch.Tensor = None,\n",
        "        labels: torch.Tensor = None,\n",
        "        compute_predictions: bool = False,\n",
        "        compute_loss: bool = True,\n",
        "        mask: torch.Tensor = None,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ) -> torch.Tensor:\n",
        "        # group model inputs and pass to the model\n",
        "        model_kwargs = {\n",
        "          \"input_ids\": input_ids,\n",
        "          \"attention_mask\": attention_mask\n",
        "        }\n",
        "        # not every model supports token_type_ids\n",
        "        if token_type_ids is not None:\n",
        "          model_kwargs[\"token_type_ids\"] = token_type_ids\n",
        "        transformers_outputs = self.transformer_model(**model_kwargs) # batch_size X max_len X 768\n",
        "        # we would like to use the sum of the last four hidden layers\n",
        "        transformers_outputs_sum = torch.stack(transformers_outputs.hidden_states[-4:], dim=0).sum(dim=0)\n",
        "        transformers_outputs_sum = self.dropout(transformers_outputs_sum)\n",
        "\n",
        "        #I get the attentio matrix\n",
        "        attention_matrix = transformers_outputs.attentions[-1].transpose(1,2).transpose(2,3) # batch_size X  X max_len X max_len x num_heads\n",
        "        attention_matrix = self.dropout(self.relu(self.fcAttention1(attention_matrix)))\n",
        "\n",
        "        #I compute the element-wise matrix\n",
        "        # seq_len = transformers_outputs_sum.shape[1]\n",
        "        # transformers_outputs_sum_1 = transformers_outputs_sum[:].unsqueeze(1).repeat(1, seq_len, 1, 1)# batch_size X max_len X 1 X 768\n",
        "        # transformers_outputs_sum_2 = transformers_outputs_sum[:].unsqueeze(2).repeat(1, 1, seq_len, 1)# batch_size X 1 X max_len X 768\n",
        "        # transformers_outputs_sum_3 = transformers_outputs_sum_1 * transformers_outputs_sum_2\n",
        "\n",
        "        transformers_outputs_sum_3 = torch.einsum('bik,bjk->bijk', transformers_outputs_sum, transformers_outputs_sum)\n",
        "\n",
        "        #Concat the 2 matrix\n",
        "        # concat = torch.concatenate((transformers_outputs_sum_3, attention_matrix), axis=-1)\n",
        "\n",
        "        concat = attention_matrix * transformers_outputs_sum_3\n",
        "\n",
        "        # 2 Linear layers to decrease the size and finally thr classifier\n",
        "        concat = self.dropout(self.relu(self.fc1(concat)))\n",
        "        concat = self.dropout(self.relu(self.fc2(concat)))\n",
        "        logits = self.classifier(concat)\n",
        "\n",
        "        output = {\"logits\": logits}\n",
        "\n",
        "        if compute_predictions:\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "            output[\"predictions\"] = predictions\n",
        "\n",
        "        if compute_loss and labels is not None:\n",
        "            output[\"loss\"] = self.compute_loss(logits, labels)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def compute_loss(\n",
        "        self, logits: torch.Tensor, labels: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the loss of the model.\n",
        "        Args:\n",
        "            logits (`torch.Tensor`):\n",
        "                The logits of the model.\n",
        "            labels (`torch.Tensor`):\n",
        "                The labels of the model.\n",
        "        Returns:\n",
        "            obj:`torch.Tensor`: The loss of the model.\n",
        "        \"\"\"\n",
        "        return F.cross_entropy(\n",
        "            logits.view(-1, self.num_labels),\n",
        "            labels.view(-1).to(torch.long),\n",
        "            ignore_index=-100,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline model"
      ],
      "metadata": {
        "id": "5CeQYTo7tsXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FranzModel(torch.nn.Module):\n",
        "    def __init__(self, language_model_name: str, num_labels: int, fine_tune_lm: bool = True, *args, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        # layers\n",
        "        self.transformer_model = AutoModel.from_pretrained(language_model_name, output_hidden_states=True, output_attentions=True)\n",
        "        if not fine_tune_lm:\n",
        "            for param in self.transformer_model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "        self.dense = torch.nn.Linear(768, 768, bias=True)\n",
        "        self.classifier = torch.nn.Linear(768, num_labels, bias=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor = None,\n",
        "        attention_mask: torch.Tensor = None,\n",
        "        token_type_ids: torch.Tensor = None,\n",
        "        labels: torch.Tensor = None,\n",
        "        compute_predictions: bool = False,\n",
        "        compute_loss: bool = True,\n",
        "        mask: torch.Tensor = None,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ) -> torch.Tensor:\n",
        "        # group model inputs and pass to the model\n",
        "        model_kwargs = {\n",
        "          \"input_ids\": input_ids,\n",
        "          \"attention_mask\": attention_mask\n",
        "        }\n",
        "        # not every model supports token_type_ids\n",
        "        if token_type_ids is not None:\n",
        "          model_kwargs[\"token_type_ids\"] = token_type_ids\n",
        "        transformers_outputs = self.transformer_model(**model_kwargs) # batch_size X max_len X 768\n",
        "\n",
        "        # we would like to use the sum of the last four hidden layers\n",
        "        transformers_outputs_sum = torch.stack(transformers_outputs.hidden_states[-4:], dim=0).sum(dim=0)\n",
        "        transformers_outputs_sum = self.dropout(transformers_outputs_sum)\n",
        "\n",
        "        # transformers_outputs_sum = transformers_outputs.hidden_states[-1]\n",
        "        # print(transformers_outputs_sum.shape)\n",
        "\n",
        "        batch_result_tensor = torch.einsum('bik,bjk->bijk', transformers_outputs_sum, transformers_outputs_sum)\n",
        "        # print(batch_result_tensor.shape)\n",
        "\n",
        "        batch_result_tensor = self.dropout(self.dense(batch_result_tensor))\n",
        "        logits = self.classifier(batch_result_tensor)\n",
        "\n",
        "        output = {\"logits\": logits}\n",
        "\n",
        "        if compute_predictions:\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "            output[\"predictions\"] = predictions\n",
        "\n",
        "        if compute_loss and labels is not None:\n",
        "            output[\"loss\"] = self.compute_loss(logits, labels)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def compute_loss(\n",
        "        self, logits: torch.Tensor, labels: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the loss of the model.\n",
        "        Args:\n",
        "            logits (`torch.Tensor`):\n",
        "                The logits of the model.\n",
        "            labels (`torch.Tensor`):\n",
        "                The labels of the model.\n",
        "        Returns:\n",
        "            obj:`torch.Tensor`: The loss of the model.\n",
        "        \"\"\"\n",
        "        return F.cross_entropy(\n",
        "            logits.view(-1, self.num_labels),\n",
        "            labels.view(-1).to(torch.long),\n",
        "            ignore_index=-100,\n",
        "        )"
      ],
      "metadata": {
        "id": "O9C4CbpRtvuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1hbKDRS-uR"
      },
      "source": [
        "## Dataloader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aePh_hjZocYQ"
      },
      "outputs": [],
      "source": [
        "datasetReDev = DatasetRe(tokens_s, relations_s)\n",
        "datasetReTest = DatasetRe(test_tokens_s, test_relations_s)\n",
        "datasetReTrain = DatasetRe(train_tokens_s, train_relations_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3edA36h1NXC2"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "  '''\n",
        "  Each sample in the batch has a List[str] corresponding to the original sentence,\n",
        "  a labels which is matrix that express the relations between subects and objects\n",
        "  '''\n",
        "\n",
        "  sentences = [d[0] for d in data]\n",
        "  relations = [d[1] for d in data]\n",
        "  tokenized = tokenizer(sentences, return_tensors=\"pt\",\n",
        "                                    padding='longest',\n",
        "                                    is_split_into_words=True)\n",
        "\n",
        "  words_ids = [\n",
        "    tokenized[i].word_ids\n",
        "    for i in range(len(tokenized['input_ids']))\n",
        "  ]\n",
        "\n",
        "  table_re = genTrueLabels(tokenized, relations, words_ids)\n",
        "\n",
        "  rets = {\n",
        "      'sentences': sentences,\n",
        "      'table_re': table_re\n",
        "  }\n",
        "\n",
        "  return rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaLzDGP_E2wO"
      },
      "outputs": [],
      "source": [
        "dataloaderDev = DataLoader(\n",
        "    datasetReDev,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "dataloaderTest = DataLoader(\n",
        "    datasetReTest,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "dataloaderTrain = DataLoader(\n",
        "    datasetReTrain,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iwOgHT_PNFI"
      },
      "source": [
        "## RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDjQWGI0mSx_"
      },
      "source": [
        "### Model Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIW7Z7zEmZ1w"
      },
      "outputs": [],
      "source": [
        "# model = REWise(\"bert-base-uncased\", len(rel2idx), fine_tune_lm=False).to(hypers.device)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = REWise(language_model, len(rel2idx), fine_tune_lm=False).to(hypers.device)\n",
        "# model = FranzModel(language_model, len(rel2idx), fine_tune_lm=False).to(hypers.device)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(language_model, add_prefix_space=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hypers.learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIn2-R08u4r8"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgyJ0HhFVN3r"
      },
      "outputs": [],
      "source": [
        "pretrained_weights = torch.load('/content/drive/MyDrive/AI/NLP_HW3/re_table_noncela_9.pth', map_location=torch.device(hypers.device))\n",
        "\n",
        "  # Load the weights into your model\n",
        "model.load_state_dict(pretrained_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Train"
      ],
      "metadata": {
        "id": "s_E8Xt-uXJ0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "best_loss = float('+inf')\n",
        "train_losses = []\n",
        "for epoch in range(5,7):\n",
        "  bar_tqdm = tqdm(enumerate(dataloaderTrain), total = len(dataloaderTrain), position = 0, leave = True)\n",
        "\n",
        "  for i, batch in bar_tqdm:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    sentences = batch['sentences']\n",
        "    re_labels = batch['table_re']\n",
        "\n",
        "    tokens = tokenizer(sentences,\n",
        "                      return_tensors=\"pt\",\n",
        "                      padding=True,\n",
        "                      is_split_into_words=True)\n",
        "\n",
        "    tokens['labels'] = re_labels\n",
        "\n",
        "    batch = {k: v.to(hypers.device) for k, v in tokens.items()}\n",
        "\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs[\"loss\"]\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f'iteration: {i}, loss: {loss.item()}')\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  # test_loss = test(model, dataloaderDev)\n",
        "  # print(f'train_loss: {np.array(train_losses).mean()}, test_loss: {test_loss}, best_loss: {best_loss}')\n",
        "  # if test_loss < best_loss:\n",
        "  #   print(\"best loss found\")\n",
        "  #   best_loss = test_loss\n",
        "  save_path = f'/content/drive/MyDrive/AI/NLP_HW3/re_table_franz_wise_combo_lr_low_{epoch}.pth'\n",
        "  torch.save(model.state_dict(), save_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "9FVHnwHiXNx3",
        "outputId": "58ec543a-9eec-4975-df96-ebe6f76829af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/7025 [00:00<14:08,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0, loss: 0.012628231197595596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 102/7025 [00:09<09:44, 11.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 100, loss: 0.00919689703732729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 202/7025 [00:17<08:45, 12.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 200, loss: 0.00552060641348362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 301/7025 [00:26<09:36, 11.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 300, loss: 0.009421775117516518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 402/7025 [00:35<09:30, 11.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 400, loss: 0.00416558887809515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 502/7025 [00:43<08:28, 12.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 500, loss: 0.006601123604923487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 566/7025 [00:49<09:21, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-971200c6a886>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'iteration: {i}, loss: {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# test_loss = test(model, dataloaderDev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_losses = []\n",
        "model.eval()\n",
        "\n",
        "all_relations_pred_labels = []\n",
        "all_relations_pred = []\n",
        "\n",
        "for i, batch in tqdm(enumerate(dataloaderTest), total = len(dataloaderTest), position = 0, leave = True):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  sentences = batch['sentences']\n",
        "  # ner_labels = batch['ner_labels']\n",
        "  re_labels = batch['table_re']\n",
        "\n",
        "  tokens = tokenizer(sentences,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    is_split_into_words=True)\n",
        "\n",
        "  tokens['labels'] = re_labels\n",
        "\n",
        "  words_ids = [\n",
        "    tokens[i].word_ids\n",
        "    for i in range(len(tokens['input_ids']))\n",
        "  ]\n",
        "\n",
        "  batch = {k: v.to(hypers.device) for k, v in tokens.items()}\n",
        "  batch['compute_loss'] = True\n",
        "  batch['compute_predictions'] = True\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**batch)\n",
        "  loss = outputs[\"loss\"]\n",
        "  pred = outputs[\"predictions\"]\n",
        "\n",
        "  #Extract Original Relations\n",
        "  labels_indices = getLabelsIndices(batch['labels'])\n",
        "  prediction_indices = torch.where(pred != 0)\n",
        "\n",
        "  all_relations_pred_labels += computeRelations(labels_indices, batch['labels'], words_ids)\n",
        "  all_relations_pred += computeRelations(prediction_indices, pred, words_ids)\n",
        "\n",
        "  all_test_losses.append(loss.item())\n",
        "  if i % 100 == 0:\n",
        "    print(f'iteration: {i}, loss: {loss.item()}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uu17aoZF3-C",
        "outputId": "212fa64c-caca-4d73-e9e8-cccbfc66d793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 4/250 [00:00<00:16, 14.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0, loss: 0.005053708329796791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 102/250 [00:04<00:07, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 100, loss: 0.0037056799046695232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 205/250 [00:09<00:02, 19.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 200, loss: 0.011923396028578281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:12<00:00, 20.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score(all_relations_pred_labels, all_relations_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjuGVqErF6Ei",
        "outputId": "9fca4feb-2bdf-4290-e3c3-7f5bf5e34ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4136742315426601, 0.38095238095238093, 0.4525455688246386)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNU4-0cUu7gx"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9T8nH152D5f",
        "outputId": "d39ecb6d-c936-41cb-9d8a-dfe905f0b025"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "pretrained_weights = torch.load('/content/drive/MyDrive/AI/NLP_HW3/re_table_franz_dev_1.pth', map_location=torch.device(hypers.device))\n",
        "model.load_state_dict(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJn9EjdXWNHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6de1d0-5aaa-43f3-9abe-217089d375b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/250 [00:00<00:25,  9.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0, loss: 0.004184530582278967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 102/250 [00:06<00:10, 13.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 100, loss: 0.00247001089155674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 203/250 [00:12<00:03, 14.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 200, loss: 0.010397104546427727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:16<00:00, 15.37it/s]\n"
          ]
        }
      ],
      "source": [
        "all_test_losses = []\n",
        "model.eval()\n",
        "\n",
        "all_relations_pred_labels = []\n",
        "all_relations_pred = []\n",
        "\n",
        "for i, batch in tqdm(enumerate(dataloaderTest), total = len(dataloaderTest), position = 0, leave = True):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  sentences = batch['sentences']\n",
        "  # ner_labels = batch['ner_labels']\n",
        "  re_labels = batch['table_re']\n",
        "\n",
        "  tokens = tokenizer(sentences,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    is_split_into_words=True)\n",
        "\n",
        "  tokens['labels'] = re_labels\n",
        "\n",
        "  words_ids = [\n",
        "    tokens[i].word_ids\n",
        "    for i in range(len(tokens['input_ids']))\n",
        "  ]\n",
        "\n",
        "  batch = {k: v.to(hypers.device) for k, v in tokens.items()}\n",
        "  batch['compute_loss'] = True\n",
        "  batch['compute_predictions'] = True\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**batch)\n",
        "  loss = outputs[\"loss\"]\n",
        "  pred = outputs[\"predictions\"]\n",
        "\n",
        "  #Extract Original Relations\n",
        "  labels_indices = getLabelsIndices(batch['labels'])\n",
        "  prediction_indices = torch.where(pred != 0)\n",
        "\n",
        "  all_relations_pred_labels += computeRelations(labels_indices, batch['labels'], words_ids)\n",
        "  all_relations_pred += computeRelations(prediction_indices, pred, words_ids)\n",
        "\n",
        "  all_test_losses.append(loss.item())\n",
        "  if i % 100 == 0:\n",
        "    print(f'iteration: {i}, loss: {loss.item()}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-dSNEVxtEwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9491d1-8ce3-4a5d-cb87-eef7c57044d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4257320588681535, 0.41155764153710767, 0.4409176618478944)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "score(all_relations_pred_labels, all_relations_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline Approach**"
      ],
      "metadata": {
        "id": "4AgaDx7YomZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries"
      ],
      "metadata": {
        "id": "2hDEG04GOsD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SapienzaNLP/nlp2023-hw3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnfyuXo5xpDK",
        "outputId": "ab28a843-c12e-4f68-89fd-f4cdddebb9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp2023-hw3'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 20 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (23/23), 8.01 MiB | 10.04 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFIY1Z6WozFG",
        "outputId": "0822b1d1-f2fb-4a10-bdfa-ebf3867af9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=48db206e80673d54d14dce495791058065faa11eebc42a2b3fef4c65b7ad5e8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgX4YbefNjGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594ade85-07ab-4fdf-c9ab-b2742cd73bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import savefig\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gdown\n",
        "import seaborn as sns\n",
        "import pprint\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score as seq_f1\n",
        "from transformers import AutoTokenizer, BertTokenizerFast, BertForTokenClassification, AutoModel, BertForSequenceClassification\n",
        "from seqeval.scheme import IOB2, IOB1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "SEED:int = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehe--lE2c4pd"
      },
      "source": [
        "##From sentence to vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHojru7QntP1"
      },
      "outputs": [],
      "source": [
        "#Convert original words into vocabulary indices\n",
        "def fromWordToVocab(sentence, vocab): #cambia in sentence2vocab\n",
        "  new_sentence = [vocab[p] for p in sentence]\n",
        "  return new_sentence\n",
        "\n",
        "def fromVocabToWord(sentence, idx2vocab):\n",
        "  new_sentence = [idx2vocab[p] for p in sentence]\n",
        "  return new_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "8t1dMxBDWDXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "class hypers:\n",
        "\n",
        "    input_size = 5\n",
        "    hidden_size = 512\n",
        "    num_layers = 2\n",
        "    num_classes = 5\n",
        "\n",
        "    dropout_rate = 0.2\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    epochs = 50\n",
        "    batch_size = 64\n",
        "    print_step = 100\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "elO4Su-LWDXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aIjs7f7tkHF"
      },
      "source": [
        "## Phase 1: NER"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer and dictionaries"
      ],
      "metadata": {
        "id": "D8zOt9G2rV1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Dictionary for labels\n",
        "label2idx = {\"O\":0, \"B-ENT\":1, \"I-ENT\":2}\n",
        "idx2label = {0: \"O\", 1: \"B-ENT\", 2: \"I-ENT\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2e2dfe9d2cb0408884e5052f11317b8f",
            "7e853c220b554314bac153a2b441a9a5",
            "27607b07d03f4891ab4cd5f1d93b9a60",
            "d08e199f23f84a4c81f78d65f84fb470",
            "425bc84678b64919abf1fa0f51b42625",
            "4b0b6173acd84404bd71add845f63a79",
            "d5747149c2fc401c989f69eb18fd8df4",
            "ee820f14282147db9930165cf91c90f2",
            "5c02a6492815443ea393f0a65139a74b",
            "4755624b8d584ec4af0902eab12eb88c",
            "ecd9067a91b44dcdb47a77cec6540c4e",
            "90ea2580fafd41bf8ff3ac4dc3f7071d",
            "a84098a677a5471a92f97056ce904d5b",
            "2051a1b85ac949e6a2dfe5fca512da92",
            "f4e19e06202d495a964744cc33d291c6",
            "838824b2f35a4e16baff40b1dee6da5f",
            "a5cb9f0f3d23488cbb3ef286c13397c8",
            "5f935261a5924134a28b231f4781ddc1",
            "4cc973f995d84953b20f0faf835faef4",
            "e6a046601eb54827b980db6cacd35dae",
            "5a3b852279c74883a4e396050ede4c67",
            "76f3ef6b73ed40ae87c047d12e05a3f0",
            "9ba66a218a6d4042912bc4bc8842582e",
            "1cc58e883a434c3aaa59936d702293f5",
            "25806b42b4e944bcb4ef690ff19fb3bd",
            "711ad046420c466ca92810e3188bcc49",
            "0cccd73fd4834371b3c237bd483833de",
            "1fd2222efe6e4e8c95178f7a0a69551e",
            "9e59a7dfa2f34c5485c5029108efdfd4",
            "f8f748bf33c44e518f91f601618600bd",
            "259d848b9720450e8930a988bfed4a23",
            "ee95d8e32a13411a97d58dcb24cac295",
            "e0d15cc900f34f868815d2d93e071e69",
            "bd034a75481041edad184b1ead61653d",
            "d32a2eb0167b48d6a2e6969a65606af2",
            "462c527619a548e082180b1bb9bd4108",
            "62ae96a9c6cb40569c8d47ade07d187d",
            "86c1b45b2a8b41dea3021bf365ae2048",
            "62feb561c677425ab20c7ca67670ef40",
            "ad60dff3e5e24588be958e61c6fbb726",
            "8825a92202994080b34dfdaae7bffe14",
            "6abd518a87264428a6022deb00af6837",
            "dd5d6101dc6f4c13b3116836fdf6a3d4",
            "ab73b14099de497f9dc614010a91b459"
          ]
        },
        "id": "BhK4KVjnrZCo",
        "outputId": "39afa74b-9b8b-49dc-e9e1-1fa57955c7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e2dfe9d2cb0408884e5052f11317b8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ea2580fafd41bf8ff3ac4dc3f7071d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ba66a218a6d4042912bc4bc8842582e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd034a75481041edad184b1ead61653d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloader"
      ],
      "metadata": {
        "id": "YzTCgRBvYp4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetDownloader():\n",
        "  '''\n",
        "  This class download the dataset and creates all the labels for the NER task\n",
        "  '''\n",
        "\n",
        "  def __init__(self, path, label2idx):\n",
        "    self.data = self.downloadDataset(path)\n",
        "    self.label2idx = label2idx\n",
        "\n",
        "  def generateLabels(self):\n",
        "    for i, sample in tqdm(enumerate(self.data), total = len(self.data)):\n",
        "      tokens = sample[\"tokens\"]\n",
        "      relations = sample[\"relations\"]\n",
        "\n",
        "      labels = self.getTrueLabels(tokens, relations, self.label2idx)\n",
        "\n",
        "      self.data[i]['labels'] = labels\n",
        "    return\n",
        "\n",
        "  def getTrueLabels(self, tokens, rel, label2idx):\n",
        "    #Create the labels converting from \"B-NET\" AND \"I-ENT\" to their relative indices\n",
        "    labels = []\n",
        "    labels = [\"O\" for i in tokens]\n",
        "\n",
        "    #Loop over all relations\n",
        "    for relation in rel:\n",
        "      sub, obj = relation[\"subject\"], relation[\"object\"]\n",
        "      sub_span = [sub[\"start_idx\"], sub[\"end_idx\"]]\n",
        "      obj_span = [obj[\"start_idx\"], obj[\"end_idx\"]]\n",
        "\n",
        "      for i, tok in enumerate(tokens):\n",
        "        if i == sub_span[0]:\n",
        "          labels[i] = \"B-ENT\"\n",
        "          for k in range(i, sub_span[1]):\n",
        "            labels[k] = \"I-ENT\"\n",
        "        if i == obj_span[0]:\n",
        "          labels[i] = \"B-ENT\"\n",
        "          for k in range(i, obj_span[1]):\n",
        "            labels[k] = \"I-ENT\"\n",
        "\n",
        "\n",
        "    labels_enc = [label2idx[p] for p in labels] #From sentence to vocab\n",
        "    return labels_enc\n",
        "\n",
        "  def setVocab(self, label2idx):\n",
        "    self.label2idx = label2idx\n",
        "\n",
        "  def downloadDataset(self, path):\n",
        "    data = []\n",
        "    for line in open(path):\n",
        "      data.append(json.loads(line))\n",
        "    return data"
      ],
      "metadata": {
        "id": "Lrljqp_cYrkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSyMyga7-p0b"
      },
      "source": [
        "###Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qRnow5M-pNH"
      },
      "outputs": [],
      "source": [
        "class NerDataset(Dataset):\n",
        "  '''\n",
        "  Dataset class for NER task\n",
        "  '''\n",
        "\n",
        "  def __init__(self, data, label2idx):\n",
        "    self.data = data\n",
        "    self.label2idx = label2idx\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data = self.data[idx]\n",
        "\n",
        "    tokens = data[\"tokens\"]\n",
        "    labels = data[\"labels\"]\n",
        "\n",
        "    return tokens, labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def get_original_item(self, idx):\n",
        "     data = self.data[idx]\n",
        "     return data[\"tokens\"], data[\"relations\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNu3dC8fR3X4"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  tokens, labels_enc = zip(*batch)\n",
        "\n",
        "  labels = []\n",
        "  tokenized = tokenizer(tokens, padding=True, return_tensors=\"pt\", is_split_into_words=True)\n",
        "\n",
        "  #Loop over all the batch\n",
        "  for i, label in enumerate(labels_enc):\n",
        "    word_ids_sentence_i =  tokenized.word_ids(batch_index=i)\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "\n",
        "    for word_idx in word_ids_sentence_i:\n",
        "        #PAD, [CLS], [SEP] are set to -100\n",
        "        if word_idx is None:\n",
        "          label_ids.append(-100)\n",
        "        # Every beginning token for B-ENT and I-ENT are set to thei relative labels\n",
        "        elif word_idx != previous_word_idx:\n",
        "          label_ids.append(label[word_idx])\n",
        "        # Sub-tokens for labels generated by the tokenizer are set to -100\n",
        "        else:\n",
        "          label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  final_labels = pad_sequence(torch.tensor(labels), batch_first=True, padding_value=-100)\n",
        "\n",
        "  return tokenized, final_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4n1MxEjEdfm"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh5MQKMuE93A"
      },
      "outputs": [],
      "source": [
        "class NerModel(nn.Module):\n",
        "  def __init__(self, label_size, len_tokenizer, device, load=False):\n",
        "    super().__init__()\n",
        "    self.label_size = label_size\n",
        "    self.transformer = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=label_size) #it contains a dropout with p=0.1\n",
        "    self.transformer.resize_token_embeddings(len_tokenizer)\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, x, labels=None, compute_loss=True, compute_predictions=False):\n",
        "    input_ids = x[\"input_ids\"].to(self.device, dtype=torch.long)\n",
        "    attention_mask = x[\"attention_mask\"].to(self.device, dtype=torch.long)\n",
        "\n",
        "    #Use a BertForTokenClassification to classify the entities\n",
        "    if compute_loss:\n",
        "      labels = labels.long()\n",
        "      out = self.transformer(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "      return out\n",
        "\n",
        "    #Compute the predictions\n",
        "    if compute_predictions:\n",
        "      outputs = self.transformer(input_ids, attention_mask=attention_mask)\n",
        "      logits = outputs[0].view(-1, self.label_size)\n",
        "      predictions = logits.argmax(-1)\n",
        "      return logits, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAQlB6WR-vzT"
      },
      "source": [
        "###Handler class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HandlerNer():\n",
        "  '''\n",
        "  This class implements the methods to train and validate the model.\n",
        "  it also instantiates the optimizer and print the metrics during the training.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, model, label2idx, tokenizer, device, num_ckpt=0):\n",
        "    self.model = model\n",
        "    self.device = device\n",
        "    self.label2idx = label2idx\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def setDataset(self, train_dataset, valid_dataset, epochs):\n",
        "    self.train_dataset = train_dataset\n",
        "    self.valid_dataset = valid_dataset\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def train(self, config=None):\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), 0.0001)\n",
        "    self.train_epoch()\n",
        "    return\n",
        "\n",
        "  def train_epoch(self):\n",
        "    print(\"Start Training\")\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "\n",
        "      losses = []\n",
        "      accuracies = []\n",
        "\n",
        "      self.model.train()\n",
        "\n",
        "      #Train over the batches\n",
        "\n",
        "      for i, batch in tqdm(enumerate(self.train_dataset), total=len(self.train_dataset), desc=\"Batch\"):\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):\n",
        "          input, label = batch\n",
        "          input = input.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "\n",
        "          out = self.model(input, label)\n",
        "        loss, logits = out[0], out[1]\n",
        "\n",
        "        # Get the predictions\n",
        "        label = label.view(-1)\n",
        "        logits = logits.view(-1, self.model.label_size)\n",
        "        preds = logits.argmax(axis=1)\n",
        "\n",
        "        # Create a mask to remove the paddings\n",
        "        mask = label != -100\n",
        "\n",
        "        labels = label[mask]\n",
        "        predictions = preds[mask]\n",
        "\n",
        "        # compute accuracy\n",
        "        accuracies.append(accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()))\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        del preds\n",
        "        del labels\n",
        "        del logits\n",
        "        del mask\n",
        "\n",
        "      train_loss_mean = np.array(losses).mean()\n",
        "      train_accuracy_mean = np.array(accuracies).mean()\n",
        "      valid_loss_mean, eval_accuracy_mean, micro_f1 = self.validate(self.valid_dataset)\n",
        "\n",
        "      print(f'train_loss: {train_loss_mean:0.4f}  val_oss: {valid_loss_mean:0.4f} \\n train_acc: {train_accuracy_mean:0.4f} val_acc: {eval_accuracy_mean:0.4f} \\n F1: {micro_f1:0.4f}')\n",
        "\n",
        "    print(\"End Training\")\n",
        "    return\n",
        "\n",
        "  def validate(self, valid_dataset):\n",
        "    self.model.eval()\n",
        "\n",
        "    total_preds, total_labels = [], []\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "\n",
        "    print(\"Start Validation\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for idx, batch in tqdm(enumerate(valid_dataset), total = len(valid_dataset)):\n",
        "        input, label = batch\n",
        "        input = input.to(self.device)\n",
        "        label = label.to(self.device)\n",
        "\n",
        "        out = self.model(input, label)\n",
        "        loss, logits = out[0], out[1]\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # get the predictions\n",
        "        label = label.view(-1)\n",
        "        logits = logits.view(-1, self.model.label_size)\n",
        "        preds = torch.argmax(logits, axis=1)\n",
        "\n",
        "        # create a mask to filter the paddings\n",
        "        mask = label.view(-1) != -100\n",
        "\n",
        "        labels = torch.masked_select(label, mask)\n",
        "        predictions = torch.masked_select(preds, mask)\n",
        "\n",
        "        labels = label[mask]\n",
        "        predictions = preds[mask]\n",
        "\n",
        "        total_labels.extend(labels.tolist())\n",
        "        total_preds.extend(predictions.cpu().tolist())\n",
        "\n",
        "        # compute accuracy\n",
        "        accuracies.append(accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()))\n",
        "\n",
        "    #compute f1_score converting from vocabulary indices to Original NER tokens (i.e. \"B-ENT\")\n",
        "    micro_f1 = seq_f1([fromVocabToWord(total_preds, idx2label)], [fromVocabToWord(total_labels, idx2label)], mode=\"strict\", average=\"micro\", scheme=IOB2)\n",
        "\n",
        "    print(\"End Validation\")\n",
        "    return np.array(losses).mean(), np.array(accuracies).mean(), micro_f1\n",
        "\n",
        "  def predict(self, x):\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "          logits, predictions = self.model(x, compute_loss = False, compute_predictions=True)\n",
        "          return logits, predictions\n"
      ],
      "metadata": {
        "id": "vDGLlqVRoSE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate Dataset"
      ],
      "metadata": {
        "id": "n9hcFcKFN5b2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYSWLw2COXfh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f0412a7f0f9744b2a78dd5ae07fde4c4",
            "262b21d4174c4ff8bdc2ae21078da5fd",
            "9639c234e0024c95824dc2fcfb596bc8",
            "a0908c229b9b4773acd3565523f16bc6",
            "dd8b75fb04fc4bb89a353e8e6cdbad8f",
            "9c12d0b98d924529af862566d543cb4c",
            "5b339121ae074730ab86ec11e4799ee8",
            "3926b471ec6c438da0e23fd35b1ee9b1",
            "3567692891e341758b5dd97e700eefdd",
            "545912e89fc04513bb1211e2527a79d3",
            "aa2dd60564224d6595c512000b0d419c",
            "2564d2ca51c64a779feed3c2f72e1cc8",
            "73a83d01ee214c30a52d888a683e4fba",
            "539d0a994a364af79f8f2cd467a312c7",
            "40e13fb8250d463ea089a33c65e84eaa",
            "b2644843c66741de92195d6e8afd1291",
            "075ebce929964b16bbf05f4117fd2f1f",
            "a9be13f59ac045428257ab2c7271de21",
            "f5858d1bedb94715ab0bf6ee9d2e4c87",
            "cb8018b59bee4828a1b381892df6c7bf",
            "131b0313f408444c92049a59bdde2069",
            "4810b579d2e0448c8a8385725b6befa9",
            "6324d090e5954d5287b02313da1efa25",
            "51b1cb64646d43388ecd280eddc5c799",
            "0b90de50101147febce3442305f91c05",
            "e8dd8ae3c2f24713bae7f8f16f46fca7",
            "15ad0c5911c54c7f97089e7d59efc80f",
            "7a59940fc61742a2b612bd1620732ab3",
            "9ac2d16371e646d184bd26f1d87521cf",
            "77c19ce67a064fa3af2d29567bc9e88e",
            "f2963b7ea5b74f3dbb838afac9edcbfa",
            "887211dad4f24a0697657fe5300d0154",
            "4ad8d0e80bf144629a206f31efabbb68"
          ]
        },
        "outputId": "21cd32b3-6b48-4202-9a26-1c45eee10d76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/56196 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0412a7f0f9744b2a78dd5ae07fde4c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2564d2ca51c64a779feed3c2f72e1cc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6324d090e5954d5287b02313da1efa25"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_downloader = DatasetDownloader(\"nlp2023-hw3/data/train.jsonl\", label2idx)\n",
        "valid_downloader = DatasetDownloader(\"nlp2023-hw3/data/dev.jsonl\", label2idx)\n",
        "test_downloader = DatasetDownloader(\"nlp2023-hw3/data/test.jsonl\", label2idx)\n",
        "\n",
        "train_downloader.generateLabels()\n",
        "valid_downloader.generateLabels()\n",
        "test_downloader.generateLabels()\n",
        "\n",
        "train_dataset = NerDataset(train_downloader.data, label2idx)\n",
        "valid_dataset = NerDataset(valid_downloader.data, label2idx)\n",
        "test_dataset = NerDataset(test_downloader.data, label2idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, collate_fn=collate_fn, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "L8xjWR8-h0gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITg1blpDL0fb"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the model\n",
        "model = NerModel(label_size=len(label2idx), len_tokenizer=len(tokenizer), device=hypers.device).to(hypers.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZcQZnc7df7O",
        "outputId": "cf09d213-5d14-4cb4-b8ac-c0f911ab44e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MEiYdugajqT"
      },
      "outputs": [],
      "source": [
        "#instantiate the handler\n",
        "handlerNer = HandlerNer(model=model, label2idx=label2idx, tokenizer=tokenizer, device=hypers.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO7U4__9f7_u"
      },
      "outputs": [],
      "source": [
        "handlerNer.setDataset(train_loader, valid_loader, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IW_gvOeZn7G"
      },
      "outputs": [],
      "source": [
        "handlerNer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPllfV0sbWLQ"
      },
      "source": [
        "###Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBjXIRXo9CF0",
        "outputId": "268c3c5f-aafc-4d58-f388-d519dec2f082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = NerModel(label_size=len(label2idx), len_tokenizer=len(tokenizer), device=hypers.device).to(hypers.device)\n",
        "model_weights = torch.load('/content/drive/MyDrive/AI/NLP_HW3/pipeline/final/model_0.pth', map_location=torch.device(hypers.device))\n",
        "model.load_state_dict(model_weights)\n",
        "\n",
        "handlerNer = HandlerNer(model=model, label2idx=label2idx, tokenizer=tokenizer, device=hypers.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3f7_vF5nDse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4085f4921ebc4957a04bdab901811203",
            "3873f009039242bb96d9cdbfbc7699eb",
            "6f35a92908b44951acf33a6dfb0ed9bc",
            "3cdbc52a280444eab35326e7eca9f425",
            "98283f1d8c6740d59b0a527f40874512",
            "4029f082b39c4291aa5329996263c285",
            "6124c50905e54543b41452d15afb1698",
            "c303adbc2a0649bf97d9283f324adeb9",
            "67c11dffcc6b4dc2a77b2b7422f07fdd",
            "9b09943ea2254fb7b084bb63266037c0",
            "84c373480b8e4bf8944378340d586f28"
          ]
        },
        "outputId": "7a5fe657-8e04-4cf6-8ebe-fdfeb0e73934"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4085f4921ebc4957a04bdab901811203"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "final_pred = []\n",
        "final_labels = []\n",
        "for (x, label) in tqdm(test_loader, total = len(test_loader)):\n",
        "\n",
        "        x = x.to(hypers.device)\n",
        "\n",
        "        label = label.to(hypers.device)\n",
        "        logits, preds = handlerNer.predict(x)\n",
        "\n",
        "        preds = preds.view(-1)\n",
        "        labels = label.view(-1)\n",
        "\n",
        "        indices = labels != -100\n",
        "\n",
        "        predictions = preds[indices]\n",
        "        labels = labels[indices]\n",
        "\n",
        "        final_pred.extend(predictions.cpu().tolist())\n",
        "        final_labels.extend(labels.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTyUmPoKchST"
      },
      "outputs": [],
      "source": [
        "print(classification_report([fromVocabToWord(final_pred, idx2label)],  [fromVocabToWord(final_labels, idx2label)], mode=\"strict\", scheme=IOB2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAgDEMENtySx"
      },
      "source": [
        "##Phase 2: RE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONST"
      ],
      "metadata": {
        "id": "-MboRSWet2tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_relations2id = open(\"nlp2023-hw3/data/relations2id.json\")\n",
        "rel_vocab = json.load(f_relations2id)\n",
        "f_relations2id.close()\n",
        "\n",
        "idx2rel = {v: k for k, v in rel_vocab.items()}\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Token annotations to specify to the RE model who are the entities identified by the NER Model\n",
        "tokenizer.add_tokens(['[SUB]', '[/SUB]', '[OBJ]', '[/OBJ]'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BayJNUut4TQ",
        "outputId": "ceca8a13-290b-4ef7-dd9e-355162b0ed32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECFOrC3GY73M"
      },
      "source": [
        "###RE Build"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNCTIONS USED TO BUILD THE NEW DATASET FOR RE TASK\n",
        "\n",
        "def padLabels(input_ids, labels):\n",
        "  #Add the paddings to the batch and sub-tokens\n",
        "  word_ids =  input_ids.word_ids()\n",
        "  previous_word_idx = None\n",
        "  label_ids = []\n",
        "\n",
        "  #Loop over all tokens generated by the tokenizer\n",
        "  for word_idx in word_ids:\n",
        "      # PAD, [CLS], [SEP] are set to -100\n",
        "      if word_idx is None:\n",
        "        label_ids.append(-100)\n",
        "      # Set the label for each starting token of each entity word\n",
        "      elif word_idx != previous_word_idx:\n",
        "        label_ids.append(labels[word_idx])\n",
        "      # Set all the sub-tokens equal to -100\n",
        "      else:\n",
        "        label_ids.append(-100)\n",
        "      previous_word_idx = word_idx\n",
        "\n",
        "  return torch.tensor(label_ids)\n",
        "\n",
        "def getPredictionsAndLabelsPad(input, model, label):\n",
        "    #Get the entities predicted by the NER model\n",
        "\n",
        "    tokens = tokenizer(input, return_tensors=\"pt\", is_split_into_words=True)\n",
        "\n",
        "    # Set padding and tokens equal to -100\n",
        "    labels_padded = padLabels(tokens, label)\n",
        "\n",
        "    logits, preds = model(tokens, compute_loss=False, compute_predictions=True)\n",
        "\n",
        "    # Filter out all the paddings and sub-tokens\n",
        "    indices = labels_padded != -100\n",
        "\n",
        "    predictions = preds[indices]\n",
        "    labels = labels_padded[indices]\n",
        "\n",
        "    return predictions.cpu().numpy(), labels\n",
        "\n",
        "def getPermutatedEntities(entity_idx, sentence):\n",
        "  # Get all the possibile permutations between all the entities predicted\n",
        "  permutated_entities = []\n",
        "\n",
        "  for subject_idx, object_idx in entity_idx:\n",
        "    start_subj, end_subj = subject_idx[0], subject_idx[1]\n",
        "    start_obj, end_obj = object_idx[0], object_idx[1]\n",
        "\n",
        "    subj = sentence[start_subj: end_subj]\n",
        "    obj = sentence[start_obj: end_obj]\n",
        "\n",
        "    permutated_entities.append({\"subject\": subj, \"object\": obj})\n",
        "\n",
        "  return permutated_entities\n",
        "\n",
        "def getEntitiesIndices(labels):\n",
        "    # return the indices of all the entities\n",
        "    entities_indices = []\n",
        "    entity_start = -1\n",
        "\n",
        "    for idx, label in enumerate(labels):\n",
        "        if label == \"B-ENT\":\n",
        "            if entity_start != -1:  # Save the previous entity if one is open\n",
        "                entities_indices.append([entity_start, idx])\n",
        "            entity_start = idx  # Start a new entity\n",
        "        elif label != \"I-ENT\" and entity_start != -1:\n",
        "\n",
        "            # End of the current entity\n",
        "            entities_indices.append([entity_start, idx])\n",
        "            entity_start = -1  # Reset the start index since the entity has ended\n",
        "\n",
        "    # If there's an entity that goes up to the last label, close it\n",
        "    if entity_start != -1:\n",
        "        entities_indices.append([entity_start, len(labels)])\n",
        "\n",
        "    return entities_indices\n",
        "\n",
        "def addAnnotations(sentence, entities, entities_ids, relations):\n",
        "  #Add the tokens annotations where the entities have been predicted\n",
        "\n",
        "  sentences_annotated = []\n",
        "\n",
        "  subj_temp, obj_temp = entities[\"subject\"], entities[\"object\"]\n",
        "\n",
        "  # Subject and object text for each entity\n",
        "  subj_temp = ' '.join(subj_temp)\n",
        "  obj_temp = ' '.join(obj_temp)\n",
        "\n",
        "  new_relation = []\n",
        "\n",
        "  start_subject, end_subject = entities_ids[0][0], entities_ids[0][1]\n",
        "  start_object, end_object = entities_ids[1][0], entities_ids[1][1]\n",
        "\n",
        "  for i, tok in enumerate(sentence):\n",
        "    if i == start_subject:\n",
        "      sentences_annotated.append(\"[SUB]\")\n",
        "    if i == end_subject:\n",
        "      sentences_annotated.append(\"[/SUB]\")\n",
        "    if i == start_object:\n",
        "      sentences_annotated.append(\"[OBJ]\")\n",
        "    if i == end_object:\n",
        "      sentences_annotated.append(\"[/OBJ]\")\n",
        "    sentences_annotated.append(tok)\n",
        "\n",
        "  #Loop over all the relations\n",
        "  for rel in relations:\n",
        "    sub, obj = rel[\"subject\"], rel[\"object\"]\n",
        "    relation = rel[\"relation\"]\n",
        "\n",
        "    #return the relation\n",
        "    if sub[\"text\"] == subj_temp and obj[\"text\"] == obj_temp:\n",
        "      new_relation.append(relation)\n",
        "\n",
        "  # If no relation has been found between the entities, return no_relation\n",
        "  if len(new_relation) == 0:\n",
        "      new_relation.append(\"no_relation\")\n",
        "\n",
        "  return sentences_annotated, new_relation\n",
        "\n",
        "def getAllPermutations(entities):\n",
        "  #Generate all the possibile combinations between the given entities\n",
        "  all_premutations = []\n",
        "\n",
        "  for i, elem in enumerate(entities):\n",
        "    for j, e in enumerate(entities):\n",
        "      if i != j:\n",
        "        all_premutations.append((elem, e))\n",
        "\n",
        "  return all_premutations\n",
        "\n",
        "def generateReDataset(dataset, model):\n",
        "    '''\n",
        "      generate a new complete dataset for the RE task,\n",
        "      adding the tokens annotations and 1 sentence for each pair of entities predicted by the NER model\n",
        "    '''\n",
        "\n",
        "    rel_dataset = []\n",
        "\n",
        "    #Loop over the original dataset\n",
        "    for idx, elem in tqdm(enumerate(dataset), total = len(dataset)):\n",
        "      original_tokens = elem[0]\n",
        "      original_label = elem[1]\n",
        "      relations = dataset.get_original_item(idx)[1]\n",
        "\n",
        "      # Get the entitities predicted by the NER model\n",
        "      label_pred, _ = getPredictionsAndLabelsPad(original_tokens, model, original_label)\n",
        "\n",
        "      #get the ids of subject and object predicted\n",
        "      entitiesIds = getEntitiesIndices(fromVocabToWord(label_pred, idx2label))\n",
        "\n",
        "      #all the possibile combinations for the predicted entities\n",
        "      allPermutation = getAllPermutations(entitiesIds)\n",
        "      permutatedEntities = getPermutatedEntities(allPermutation, original_tokens)\n",
        "\n",
        "      #For each pair of entities return their relation if any, else append no_relation\n",
        "      for i, entities in enumerate(permutatedEntities):\n",
        "        item = {}\n",
        "        sentence_annotated, relation_annotated = addAnnotations(original_tokens, entities, allPermutation[i], relations)\n",
        "        item[\"Sentence\"] = sentence_annotated\n",
        "        item[\"Relation\"] = relation_annotated\n",
        "        rel_dataset.append(item)\n",
        "\n",
        "    return rel_dataset"
      ],
      "metadata": {
        "id": "0Eo60FmSGK-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJGdyv8qlbAp"
      },
      "outputs": [],
      "source": [
        "#CREATE A NEW DATASET FOR THE RE TASK WITH THE ANNOTATIONS TOKENS [SUB], [OBJ]\n",
        "\n",
        "# model_ner = NerModel(label_size=len(label2idx), len_tokenizer=len(tokenizer), device=hypers.device).to(hypers.device)\n",
        "\n",
        "# model_weights = torch.load('/content/drive/MyDrive/AI/NLP_HW3/pipeline/final/model_0.pth', map_location=torch.device(hypers.device))\n",
        "# model_ner.load_state_dict(model_weights)\n",
        "\n",
        "# rel_train_dataset = generateReDataset(train_dataset, model_ner)\n",
        "# rel_val_dataset = generateReDataset(valid_dataset, model_ner)\n",
        "\n",
        "# f_train = open(\"train_rel.jsonl\", 'w')\n",
        "# f_val = open(\"val_rel.jsonl\", 'w')\n",
        "\n",
        "# for item in rel_train_dataset:\n",
        "#   f_train.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "# for item in rel_val_dataset:\n",
        "#   f_val.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "# f_train.close()\n",
        "# f_val.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aux Functions for prediction"
      ],
      "metadata": {
        "id": "ip5rp4Ees23n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predicts the entities for each sentences\n",
        "def getPredictions(input, model, tokenizer):\n",
        "\n",
        "    tokenized = tokenizer(input, return_tensors=\"pt\", padding=True, return_offsets_mapping=True, is_split_into_words=True) #tokenize the input\n",
        "\n",
        "    with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):\n",
        "      with torch.no_grad():\n",
        "        logits, preds = model(tokenized, compute_loss=False, compute_predictions=True)\n",
        "\n",
        "    #create a mask to remove paddings\n",
        "    offset = tokenized[\"offset_mapping\"].squeeze()\n",
        "    prediction_mask = (offset[:, 0] == 0) & (offset[:, 1] != 0)\n",
        "\n",
        "    #get the filtered predictions\n",
        "    filtered_predictions = predictions[prediction_mask]\n",
        "\n",
        "    return filtered_predictions.cpu().numpy()\n",
        "\n",
        "\n",
        "#perform predictions of the relation for each relation canditates tuple\n",
        "def addAnnotationsPred(sentence, entities, model, tokenizer_re):\n",
        "  sentences_annotated = []\n",
        "\n",
        "  start_subj, end_subj = entities[0][0], entities[0][1]\n",
        "  start_obj, end_obj = entities[1][0], entities[1][1]\n",
        "\n",
        "  #loop over all tokens of the sentence and add the annotation based on SUB and OBJ tokens\n",
        "  for idx, token in enumerate(sentence):\n",
        "    if idx == start_subj:\n",
        "      sentences_annotated.append(\"[SUB]\")\n",
        "    if idx == end_subj:\n",
        "      sentences_annotated.append(\"[/SUB]\")\n",
        "    if idx == start_obj:\n",
        "      sentences_annotated.append(\"[OBJ]\")\n",
        "    if idx == end_obj:\n",
        "      sentences_annotated.append(\"[/OBJ]\")\n",
        "\n",
        "    sentences_annotated.append(token)\n",
        "\n",
        "  tokenized = tokenizer_re(sentences_annotated, return_tensors=\"pt\", is_split_into_words=True) #tokenize the input\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):\n",
        "    logits, preds = model(tokenized, compute_predictions=True)\n",
        "\n",
        "\n",
        "  mask = preds != -100 #remove padding\n",
        "\n",
        "  predictions = preds[mask]\n",
        "  return predictions.cpu().numpy()\n",
        "\n",
        "def completePredict(sentence):\n",
        "      predictions = []\n",
        "\n",
        "      #Phase 1: NER\n",
        "      label_pred = getPredictions(sentence, model_ner, tokenizer_ner)\n",
        "      sentence_converted = fromVocabToWord(label_pred, idx2label)\n",
        "\n",
        "      #get the ids of subject and object predicted\n",
        "      label_ids = getEntitiesIndices(sentence_converted)\n",
        "\n",
        "      #Extract all the possible combinations of entities predicted in phase 1\n",
        "      relation_permutations = getAllPermutations(label_ids)\n",
        "\n",
        "      for i, _ in enumerate(relation_permutations):\n",
        "        elem = {}\n",
        "\n",
        "        start_subj, end_subj = relation_permutations[0][0], relation_permutations[0][1]\n",
        "        start_obj, end_obj = relation_permutations[1][0], relation_permutations[1][1]\n",
        "\n",
        "        subject = {\"start_idx\": start_subj, \"end_idx\" : end_subj}\n",
        "        obj = {\"start_idx\": start_obj, \"end_idx\" : end_obj}\n",
        "\n",
        "        #phase 2, compute the RE task\n",
        "        annotated_relations = addAnnotationsPred(sentence, relation_permutations[i], model_re, tokenizer_re)\n",
        "\n",
        "        #filter out sentences without relations\n",
        "        rel = annotated_relations != 0\n",
        "        annotated_relations = annotated_relations[rel]\n",
        "\n",
        "        if len(annotated_relations) == 0:\n",
        "          continue\n",
        "\n",
        "\n",
        "        relation_converted = fromVocabToWord(annotated_relations, idx2rel)\n",
        "\n",
        "        elem[\"subject\"] = subject\n",
        "        elem[\"relation\"] = relation_converted[0]\n",
        "        elem[\"object\"] = obj\n",
        "\n",
        "        predictions.append(elem)\n",
        "\n",
        "      return predictions"
      ],
      "metadata": {
        "id": "kzaoNyhUtB-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5, 4):\n",
        "  print(i)\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5e1cSYcg3ft",
        "outputId": "68d7ff3a-9b72-4152-ba51-43b40288546a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tupled_labels(rel_dicts):\n",
        "        tupled_labels = []\n",
        "        for rel_dict in rel_dicts:\n",
        "            subject_dict, object_dict = rel_dict[\"subject\"], rel_dict[\"object\"]\n",
        "            tupled_labels.append(\n",
        "                (\n",
        "                    (subject_dict[\"start_idx\"], subject_dict[\"end_idx\"]),\n",
        "                    rel_dict[\"relation\"],\n",
        "                    (object_dict[\"start_idx\"], object_dict[\"end_idx\"])\n",
        "                )\n",
        "            )\n",
        "        return tupled_labels\n",
        "\n",
        "def score(total_labels, total_preds):\n",
        "  true_positives = 0\n",
        "  num_golds = 0\n",
        "  num_preds = 0\n",
        "  for sent_targets, sent_predictions in zip(total_labels, total_preds):\n",
        "      #sent_targets, sent_predictions = get_tupled_labels(sent_targets), get_tupled_labels(sent_predictions)\n",
        "      true_positives += len(set(sent_targets).intersection(set(sent_predictions)))\n",
        "      num_golds += len(sent_targets)\n",
        "      num_preds += len(sent_predictions)\n",
        "      precision = true_positives / num_preds if num_preds > 0 else 0.0\n",
        "      recall = true_positives / num_golds if num_golds > 0 else 0.0\n",
        "\n",
        "      f1_score = (\n",
        "          (2 * precision * recall) / (precision + recall)\n",
        "          if precision + recall > 0\n",
        "          else 0.0\n",
        "      )\n",
        "\n",
        "  return f1_score"
      ],
      "metadata": {
        "id": "VNaOBw9EAvb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collate_fn"
      ],
      "metadata": {
        "id": "l88CYCV9rTsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_re(batch):\n",
        "  tokens, labels = zip(*batch)\n",
        "\n",
        "  tokenized = tokenizer(tokens,\n",
        "                        padding=True,\n",
        "                        return_tensors=\"pt\",\n",
        "                        is_split_into_words=True)\n",
        "\n",
        "  #pad the batch with -100\n",
        "  labels_padded = pad_sequence(torch.LongTensor(np.array(labels)), batch_first=True, padding_value=-100)\n",
        "\n",
        "  return tokenized, torch.LongTensor(np.array(labels_padded))"
      ],
      "metadata": {
        "id": "_grA7ar0rWl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47GU6b77fqFS"
      },
      "source": [
        "###RE Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxNIkfcOTacN"
      },
      "outputs": [],
      "source": [
        "class RelationDataset(Dataset):\n",
        "  '''\n",
        "  Dataset class for Relation Extraction task\n",
        "  '''\n",
        "\n",
        "\n",
        "  def __init__(self, path, relation_vocab):\n",
        "    self.rel_dataset = []\n",
        "\n",
        "    #retrieve the previously generated dataset\n",
        "    for line in open(path):\n",
        "      self.rel_dataset.append(json.loads(line))\n",
        "\n",
        "    self.relation_vocab = relation_vocab\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data = self.rel_dataset[idx]\n",
        "\n",
        "    sentence = data[\"Sentence\"]\n",
        "    relation = data[\"Relation\"]\n",
        "\n",
        "    return sentence, fromWordToVocab(relation, self.relation_vocab) #encoded relation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.rel_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-fKHP8W7jF7"
      },
      "source": [
        "###RE Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5f_tQUX8Jdg"
      },
      "outputs": [],
      "source": [
        "class ReModel(nn.Module):\n",
        "  def __init__(self, hidden_size, num_classes, len_tokenizer, device):#, checkpoint_path, load=False):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_classes = num_classes\n",
        "    self.transformer = AutoModel.from_pretrained('bert-base-uncased')\n",
        "    self.transformer.resize_token_embeddings(len_tokenizer)\n",
        "\n",
        "    self.fc1 = nn.Linear(self.transformer.config.hidden_size, self.hidden_size)\n",
        "    self.classifier = nn.Linear(self.hidden_size, self.num_classes)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, batch, compute_predictions=False):\n",
        "      model_kwargs = {\n",
        "          \"input_ids\": batch[\"input_ids\"].to(self.device, dtype=torch.long),\n",
        "          \"attention_mask\": batch[\"attention_mask\"].to(self.device, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "      x = self.transformer(**model_kwargs)[0] #last hidden state\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #Take only the [CLS] token to classify the sentence in order to identify the relation that occurs if any\n",
        "      x = x[:, 0, :]\n",
        "\n",
        "      #Linear layer and classifier\n",
        "      x = self.dropout(F.relu(self.fc1(x)))\n",
        "      out = self.classifier(x)\n",
        "\n",
        "      if compute_predictions:\n",
        "\n",
        "        logits = out.view(-1, self.num_classes)\n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        return logits, predictions\n",
        "\n",
        "      return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xPKF7UNR3nk"
      },
      "source": [
        "###Handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBOuDwNRtLlO"
      },
      "outputs": [],
      "source": [
        "class HandlerRE():\n",
        "  '''\n",
        "  This class implements the methods to train and validate the RE model.\n",
        "  it also instantiates the optimizer and print the metrics during the training.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, model, rel_vocab, tokenizer, device, num_ckpt=0):\n",
        "    self.model = model\n",
        "    self.device = device\n",
        "    self.loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    self.rel_vocab = rel_vocab\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def setDataset(self, train_dataset, valid_dataset, epochs):\n",
        "    self.train_dataset = train_dataset\n",
        "    self.valid_dataset = valid_dataset\n",
        "    self.epochs = epochs\n",
        "\n",
        "\n",
        "  def train(self, config=None):\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), 0.0001)\n",
        "    self.train_epoch()\n",
        "    return\n",
        "\n",
        "  def train_epoch(self):\n",
        "    print(\"Start training\")\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      print(f\"Start Epoch {epoch+1}\")\n",
        "      losses = []\n",
        "      accuracies = []\n",
        "\n",
        "      self.model.train()\n",
        "\n",
        "      for i, batch in tqdm(enumerate(self.train_dataset), total = len(self.train_dataset), desc=\"Batch\"):\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):\n",
        "          input, label = batch\n",
        "          input = input.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "\n",
        "          y_pred = self.model(input)\n",
        "\n",
        "        # get the predictions\n",
        "        label = label.view(-1)\n",
        "        logits = y_pred.view(-1, self.model.num_classes)\n",
        "        preds = torch.argmax(logits, axis=1)\n",
        "\n",
        "        #compute the loss\n",
        "        loss = self.loss_function(logits, label)\n",
        "\n",
        "        # Create a mask to filter out paddings and sub-tokens\n",
        "        mask = label.view(-1) != -100\n",
        "\n",
        "        labels = label[mask]\n",
        "        predictions = preds[mask]\n",
        "\n",
        "        #compute accuracy\n",
        "        accuracies.append(accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()))\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        del preds\n",
        "        del labels\n",
        "        del logits\n",
        "        del mask\n",
        "\n",
        "      train_loss_mean = np.array(losses).mean()\n",
        "      train_accuracy_mean = np.array(accuracies).mean()\n",
        "      valid_loss_mean, eval_accuracy_mean, micro_f1 = self.validate(self.valid_dataset)\n",
        "\n",
        "      print(f'train_loss: {train_loss_mean:0.4f}  val_oss: {valid_loss_mean:0.4f} \\n train_acc: {train_accuracy_mean:0.4f} val_acc: {eval_accuracy_mean:0.4f} \\n F1: {micro_f1:0.4f}')\n",
        "\n",
        "    print(\"End training\")\n",
        "    return\n",
        "\n",
        "\n",
        "  def validate(self, valid_dataset):\n",
        "    self.model.eval()\n",
        "    total_preds, total_labels = [], []\n",
        "    decoded_preds, decoded_labels = [], []\n",
        "\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "\n",
        "    print(\"Start Validation\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for idx, batch in tqdm(enumerate(valid_dataset), total = len(valid_dataset)):\n",
        "        input, label = batch\n",
        "\n",
        "        input = input.to(self.device)\n",
        "        label = label.to(self.device)\n",
        "\n",
        "        y_pred = self.model(input)\n",
        "\n",
        "        # get predictions\n",
        "        label = label.view(-1)\n",
        "        logits = y_pred.view(-1, self.model.num_classes)\n",
        "        preds = torch.argmax(logits, axis=1)\n",
        "\n",
        "        #compute the loss\n",
        "        loss = self.loss_function(logits, label)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # create a mask to remove paddings and sub-tokens\n",
        "        mask = label.view(-1) != -100\n",
        "\n",
        "        labels = label[mask]\n",
        "        predictions = preds[mask]\n",
        "\n",
        "        total_labels.extend(labels.tolist())\n",
        "        total_preds.extend(predictions.cpu().tolist())\n",
        "\n",
        "        #compute predictions\n",
        "        accuracies.append(accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()))\n",
        "\n",
        "    #compute f1_score\n",
        "    micro_f1 = f1_score(fromVocabToWord(total_preds, idx2rel), fromVocabToWord(total_labels, idx2rel), average=\"micro\")\n",
        "\n",
        "    print(\"End Validation\")\n",
        "\n",
        "    return np.array(losses).mean(), np.array(accuracies).mean(), micro_f1\n",
        "\n",
        "  def predict(self, batch):\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "          logits, predictions = self.model(batch=batch, compute_predictions=True)\n",
        "          return logits, predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate dataset"
      ],
      "metadata": {
        "id": "BTdyPeEYQwC1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjMHO9gcc75q"
      },
      "outputs": [],
      "source": [
        "rel_train_dataset = RelationDataset(\"/content/drive/MyDrive/Magistrale/Natural Language Processing/NLP-HW3/train_rel.jsonl\", rel_vocab)\n",
        "rel_val_dataset = RelationDataset(\"/content/drive/MyDrive/Magistrale/Natural Language Processing/NLP-HW3/val_rel.jsonl\", rel_vocab)\n",
        "rel_train_loader = DataLoader(rel_train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn_re)\n",
        "rel_val_loader = DataLoader(rel_val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_re)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTWvVL5G7vN-"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate RE Model\n",
        "modelRe = ReModel(hidden_size=hypers.hidden_size, num_classes=len(rel_vocab), len_tokenizer=len(tokenizer), device=hypers.device).to(hypers.device)\n",
        "\n",
        "# Instantiate RE handler\n",
        "handlerRe = HandlerRE(model = modelRe, rel_vocab=rel_vocab, tokenizer=tokenizer, device=hypers.device)\n",
        "\n",
        "# Set the dataset and the number of training epochs\n",
        "handlerRe.setDataset(rel_train_loader, rel_val_loader, 2)"
      ],
      "metadata": {
        "id": "U7idwUWC6sWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "handlerRe.train()"
      ],
      "metadata": {
        "id": "rEC2XzZyBhg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOXAJFi706b0"
      },
      "source": [
        "##A-Z Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhwWLl4HL8BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3676e9-f86c-42f0-c570-2d4545f5c22d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Load the tokenizers\n",
        "tokenizer_ner = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer_re = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer_re.add_tokens(['[SUB]', '[/SUB]', '[OBJ]', '[/OBJ]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJSqFj2S06b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd68f1c3-7c1d-4661-8753-f9791a5c6adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the models\n",
        "model_ner = NerModel(label_size = len(label2idx), len_tokenizer=len(tokenizer_ner), device=hypers.device).to(hypers.device)\n",
        "model_re = ReModel(hidden_size=hypers.hidden_size, num_classes=len(rel_vocab), len_tokenizer=len(tokenizer_re), device=hypers.device).to(hypers.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNzgwVC1UMAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af82449-ca22-4b23-d935-c71004e3bcc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "# Load the checkpoints\n",
        "checkpoint_path_ent = '/content/drive/MyDrive/AI/NLP_HW3/pipeline/final/model_0.pth'\n",
        "checkpoint_path_rel = '/content/drive/MyDrive/AI/NLP_HW3/pipeline/final/model_rel_0.pth'\n",
        "\n",
        "model_weights = torch.load(checkpoint_path_ent, map_location=torch.device(hypers.device))\n",
        "model_ner.load_state_dict(model_weights)\n",
        "\n",
        "\n",
        "model_weights = torch.load(checkpoint_path_rel, map_location=torch.device(hypers.device))\n",
        "model_re.load_state_dict(model_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTivkQUFeOGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "301b5303c9f24a26bf2d76b710a55f86",
            "a3ea6cef3e33422faed66529e6dc4c1b",
            "7c3e5755e22e45a6873ab6510be52487",
            "2fe6d50203144f08939ea45cddaed728",
            "aa09fb39dbf749d0a10e490fd38db234",
            "9738d947068f4a4596063867b101b8c7",
            "708ee827c7a24b04b73afaeb0dff77fe",
            "86806805c3a241a0a181190d0e69933c",
            "713706119e0c462f8f4bb6af5d5ecb9f",
            "7acc5aa7623d4826aba59e15441b198c",
            "dcd514be89034afb99f9e2873c91ba4a"
          ]
        },
        "outputId": "0a0e2028-78ec-45bb-9b9c-a618e942da6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "301b5303c9f24a26bf2d76b710a55f86"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "final_preds = []\n",
        "final_labels = []\n",
        "for i, (x, _) in tqdm(enumerate(test_dataset)):\n",
        "\n",
        "  pred = completePredict(x)\n",
        "\n",
        "  final_preds.append(get_tupled_labels(pred))\n",
        "  final_labels.append(get_tupled_labels(test_dataset.get_original_item(i)[1]))\n",
        "\n",
        "  if i == 10:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gboscYO0-SH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8d728c-876d-48e0-c4a1-d48d75f15349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8648648648648649\n"
          ]
        }
      ],
      "source": [
        "f1_score = score(final_labels, final_preds)\n",
        "print(f1_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ipaoJYyXzTu3",
        "j5TXd1-PmeIF",
        "eKBqcZTiVSmn",
        "3OgLSPvVGF70",
        "hOjNSS-8Q4PQ",
        "CL1pyo8jzWgc",
        "HG-RvHLTEA8m",
        "X0gjCvJ0zHRd",
        "WVelRp9O-BsS",
        "JnCdrQxa3MSv",
        "5CeQYTo7tsXA",
        "oY1hbKDRS-uR",
        "-iwOgHT_PNFI",
        "lDjQWGI0mSx_",
        "LIn2-R08u4r8",
        "s_E8Xt-uXJ0C",
        "bNU4-0cUu7gx",
        "2hDEG04GOsD_",
        "ehe--lE2c4pd",
        "8t1dMxBDWDXM",
        "2aIjs7f7tkHF",
        "D8zOt9G2rV1Q",
        "YzTCgRBvYp4J",
        "hSyMyga7-p0b",
        "V4n1MxEjEdfm",
        "GAQlB6WR-vzT",
        "n9hcFcKFN5b2",
        "ITg1blpDL0fb",
        "wPllfV0sbWLQ",
        "-MboRSWet2tW",
        "ip5rp4Ees23n",
        "l88CYCV9rTsB",
        "47GU6b77fqFS",
        "L-fKHP8W7jF7",
        "3xPKF7UNR3nk",
        "BTdyPeEYQwC1",
        "UTWvVL5G7vN-"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e2dfe9d2cb0408884e5052f11317b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e853c220b554314bac153a2b441a9a5",
              "IPY_MODEL_27607b07d03f4891ab4cd5f1d93b9a60",
              "IPY_MODEL_d08e199f23f84a4c81f78d65f84fb470"
            ],
            "layout": "IPY_MODEL_425bc84678b64919abf1fa0f51b42625"
          }
        },
        "7e853c220b554314bac153a2b441a9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0b6173acd84404bd71add845f63a79",
            "placeholder": "​",
            "style": "IPY_MODEL_d5747149c2fc401c989f69eb18fd8df4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "27607b07d03f4891ab4cd5f1d93b9a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee820f14282147db9930165cf91c90f2",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c02a6492815443ea393f0a65139a74b",
            "value": 48
          }
        },
        "d08e199f23f84a4c81f78d65f84fb470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4755624b8d584ec4af0902eab12eb88c",
            "placeholder": "​",
            "style": "IPY_MODEL_ecd9067a91b44dcdb47a77cec6540c4e",
            "value": " 48.0/48.0 [00:00&lt;00:00, 890B/s]"
          }
        },
        "425bc84678b64919abf1fa0f51b42625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0b6173acd84404bd71add845f63a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5747149c2fc401c989f69eb18fd8df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee820f14282147db9930165cf91c90f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c02a6492815443ea393f0a65139a74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4755624b8d584ec4af0902eab12eb88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd9067a91b44dcdb47a77cec6540c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ea2580fafd41bf8ff3ac4dc3f7071d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a84098a677a5471a92f97056ce904d5b",
              "IPY_MODEL_2051a1b85ac949e6a2dfe5fca512da92",
              "IPY_MODEL_f4e19e06202d495a964744cc33d291c6"
            ],
            "layout": "IPY_MODEL_838824b2f35a4e16baff40b1dee6da5f"
          }
        },
        "a84098a677a5471a92f97056ce904d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cb9f0f3d23488cbb3ef286c13397c8",
            "placeholder": "​",
            "style": "IPY_MODEL_5f935261a5924134a28b231f4781ddc1",
            "value": "vocab.txt: 100%"
          }
        },
        "2051a1b85ac949e6a2dfe5fca512da92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc973f995d84953b20f0faf835faef4",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6a046601eb54827b980db6cacd35dae",
            "value": 231508
          }
        },
        "f4e19e06202d495a964744cc33d291c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3b852279c74883a4e396050ede4c67",
            "placeholder": "​",
            "style": "IPY_MODEL_76f3ef6b73ed40ae87c047d12e05a3f0",
            "value": " 232k/232k [00:00&lt;00:00, 3.16MB/s]"
          }
        },
        "838824b2f35a4e16baff40b1dee6da5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5cb9f0f3d23488cbb3ef286c13397c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f935261a5924134a28b231f4781ddc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc973f995d84953b20f0faf835faef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a046601eb54827b980db6cacd35dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a3b852279c74883a4e396050ede4c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f3ef6b73ed40ae87c047d12e05a3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba66a218a6d4042912bc4bc8842582e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cc58e883a434c3aaa59936d702293f5",
              "IPY_MODEL_25806b42b4e944bcb4ef690ff19fb3bd",
              "IPY_MODEL_711ad046420c466ca92810e3188bcc49"
            ],
            "layout": "IPY_MODEL_0cccd73fd4834371b3c237bd483833de"
          }
        },
        "1cc58e883a434c3aaa59936d702293f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd2222efe6e4e8c95178f7a0a69551e",
            "placeholder": "​",
            "style": "IPY_MODEL_9e59a7dfa2f34c5485c5029108efdfd4",
            "value": "tokenizer.json: 100%"
          }
        },
        "25806b42b4e944bcb4ef690ff19fb3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f748bf33c44e518f91f601618600bd",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_259d848b9720450e8930a988bfed4a23",
            "value": 466062
          }
        },
        "711ad046420c466ca92810e3188bcc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee95d8e32a13411a97d58dcb24cac295",
            "placeholder": "​",
            "style": "IPY_MODEL_e0d15cc900f34f868815d2d93e071e69",
            "value": " 466k/466k [00:00&lt;00:00, 3.48MB/s]"
          }
        },
        "0cccd73fd4834371b3c237bd483833de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd2222efe6e4e8c95178f7a0a69551e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e59a7dfa2f34c5485c5029108efdfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f748bf33c44e518f91f601618600bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259d848b9720450e8930a988bfed4a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee95d8e32a13411a97d58dcb24cac295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d15cc900f34f868815d2d93e071e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd034a75481041edad184b1ead61653d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d32a2eb0167b48d6a2e6969a65606af2",
              "IPY_MODEL_462c527619a548e082180b1bb9bd4108",
              "IPY_MODEL_62ae96a9c6cb40569c8d47ade07d187d"
            ],
            "layout": "IPY_MODEL_86c1b45b2a8b41dea3021bf365ae2048"
          }
        },
        "d32a2eb0167b48d6a2e6969a65606af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62feb561c677425ab20c7ca67670ef40",
            "placeholder": "​",
            "style": "IPY_MODEL_ad60dff3e5e24588be958e61c6fbb726",
            "value": "config.json: 100%"
          }
        },
        "462c527619a548e082180b1bb9bd4108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8825a92202994080b34dfdaae7bffe14",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6abd518a87264428a6022deb00af6837",
            "value": 570
          }
        },
        "62ae96a9c6cb40569c8d47ade07d187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5d6101dc6f4c13b3116836fdf6a3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_ab73b14099de497f9dc614010a91b459",
            "value": " 570/570 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "86c1b45b2a8b41dea3021bf365ae2048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62feb561c677425ab20c7ca67670ef40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad60dff3e5e24588be958e61c6fbb726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8825a92202994080b34dfdaae7bffe14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abd518a87264428a6022deb00af6837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd5d6101dc6f4c13b3116836fdf6a3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab73b14099de497f9dc614010a91b459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0412a7f0f9744b2a78dd5ae07fde4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_262b21d4174c4ff8bdc2ae21078da5fd",
              "IPY_MODEL_9639c234e0024c95824dc2fcfb596bc8",
              "IPY_MODEL_a0908c229b9b4773acd3565523f16bc6"
            ],
            "layout": "IPY_MODEL_dd8b75fb04fc4bb89a353e8e6cdbad8f"
          }
        },
        "262b21d4174c4ff8bdc2ae21078da5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c12d0b98d924529af862566d543cb4c",
            "placeholder": "​",
            "style": "IPY_MODEL_5b339121ae074730ab86ec11e4799ee8",
            "value": "100%"
          }
        },
        "9639c234e0024c95824dc2fcfb596bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3926b471ec6c438da0e23fd35b1ee9b1",
            "max": 56196,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3567692891e341758b5dd97e700eefdd",
            "value": 56196
          }
        },
        "a0908c229b9b4773acd3565523f16bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545912e89fc04513bb1211e2527a79d3",
            "placeholder": "​",
            "style": "IPY_MODEL_aa2dd60564224d6595c512000b0d419c",
            "value": " 56196/56196 [00:01&lt;00:00, 39724.65it/s]"
          }
        },
        "dd8b75fb04fc4bb89a353e8e6cdbad8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c12d0b98d924529af862566d543cb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b339121ae074730ab86ec11e4799ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3926b471ec6c438da0e23fd35b1ee9b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3567692891e341758b5dd97e700eefdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "545912e89fc04513bb1211e2527a79d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2dd60564224d6595c512000b0d419c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2564d2ca51c64a779feed3c2f72e1cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73a83d01ee214c30a52d888a683e4fba",
              "IPY_MODEL_539d0a994a364af79f8f2cd467a312c7",
              "IPY_MODEL_40e13fb8250d463ea089a33c65e84eaa"
            ],
            "layout": "IPY_MODEL_b2644843c66741de92195d6e8afd1291"
          }
        },
        "73a83d01ee214c30a52d888a683e4fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075ebce929964b16bbf05f4117fd2f1f",
            "placeholder": "​",
            "style": "IPY_MODEL_a9be13f59ac045428257ab2c7271de21",
            "value": "100%"
          }
        },
        "539d0a994a364af79f8f2cd467a312c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5858d1bedb94715ab0bf6ee9d2e4c87",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb8018b59bee4828a1b381892df6c7bf",
            "value": 5000
          }
        },
        "40e13fb8250d463ea089a33c65e84eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131b0313f408444c92049a59bdde2069",
            "placeholder": "​",
            "style": "IPY_MODEL_4810b579d2e0448c8a8385725b6befa9",
            "value": " 5000/5000 [00:00&lt;00:00, 17544.79it/s]"
          }
        },
        "b2644843c66741de92195d6e8afd1291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075ebce929964b16bbf05f4117fd2f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9be13f59ac045428257ab2c7271de21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5858d1bedb94715ab0bf6ee9d2e4c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8018b59bee4828a1b381892df6c7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "131b0313f408444c92049a59bdde2069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4810b579d2e0448c8a8385725b6befa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6324d090e5954d5287b02313da1efa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51b1cb64646d43388ecd280eddc5c799",
              "IPY_MODEL_0b90de50101147febce3442305f91c05",
              "IPY_MODEL_e8dd8ae3c2f24713bae7f8f16f46fca7"
            ],
            "layout": "IPY_MODEL_15ad0c5911c54c7f97089e7d59efc80f"
          }
        },
        "51b1cb64646d43388ecd280eddc5c799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a59940fc61742a2b612bd1620732ab3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac2d16371e646d184bd26f1d87521cf",
            "value": "100%"
          }
        },
        "0b90de50101147febce3442305f91c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c19ce67a064fa3af2d29567bc9e88e",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2963b7ea5b74f3dbb838afac9edcbfa",
            "value": 2000
          }
        },
        "e8dd8ae3c2f24713bae7f8f16f46fca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887211dad4f24a0697657fe5300d0154",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad8d0e80bf144629a206f31efabbb68",
            "value": " 2000/2000 [00:00&lt;00:00, 25966.82it/s]"
          }
        },
        "15ad0c5911c54c7f97089e7d59efc80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a59940fc61742a2b612bd1620732ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac2d16371e646d184bd26f1d87521cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c19ce67a064fa3af2d29567bc9e88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2963b7ea5b74f3dbb838afac9edcbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887211dad4f24a0697657fe5300d0154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad8d0e80bf144629a206f31efabbb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4085f4921ebc4957a04bdab901811203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3873f009039242bb96d9cdbfbc7699eb",
              "IPY_MODEL_6f35a92908b44951acf33a6dfb0ed9bc",
              "IPY_MODEL_3cdbc52a280444eab35326e7eca9f425"
            ],
            "layout": "IPY_MODEL_98283f1d8c6740d59b0a527f40874512"
          }
        },
        "3873f009039242bb96d9cdbfbc7699eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4029f082b39c4291aa5329996263c285",
            "placeholder": "​",
            "style": "IPY_MODEL_6124c50905e54543b41452d15afb1698",
            "value": "100%"
          }
        },
        "6f35a92908b44951acf33a6dfb0ed9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c303adbc2a0649bf97d9283f324adeb9",
            "max": 63,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67c11dffcc6b4dc2a77b2b7422f07fdd",
            "value": 63
          }
        },
        "3cdbc52a280444eab35326e7eca9f425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b09943ea2254fb7b084bb63266037c0",
            "placeholder": "​",
            "style": "IPY_MODEL_84c373480b8e4bf8944378340d586f28",
            "value": " 63/63 [00:10&lt;00:00,  5.63it/s]"
          }
        },
        "98283f1d8c6740d59b0a527f40874512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4029f082b39c4291aa5329996263c285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6124c50905e54543b41452d15afb1698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c303adbc2a0649bf97d9283f324adeb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c11dffcc6b4dc2a77b2b7422f07fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b09943ea2254fb7b084bb63266037c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c373480b8e4bf8944378340d586f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "301b5303c9f24a26bf2d76b710a55f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3ea6cef3e33422faed66529e6dc4c1b",
              "IPY_MODEL_7c3e5755e22e45a6873ab6510be52487",
              "IPY_MODEL_2fe6d50203144f08939ea45cddaed728"
            ],
            "layout": "IPY_MODEL_aa09fb39dbf749d0a10e490fd38db234"
          }
        },
        "a3ea6cef3e33422faed66529e6dc4c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9738d947068f4a4596063867b101b8c7",
            "placeholder": "​",
            "style": "IPY_MODEL_708ee827c7a24b04b73afaeb0dff77fe",
            "value": ""
          }
        },
        "7c3e5755e22e45a6873ab6510be52487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86806805c3a241a0a181190d0e69933c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_713706119e0c462f8f4bb6af5d5ecb9f",
            "value": 1
          }
        },
        "2fe6d50203144f08939ea45cddaed728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7acc5aa7623d4826aba59e15441b198c",
            "placeholder": "​",
            "style": "IPY_MODEL_dcd514be89034afb99f9e2873c91ba4a",
            "value": " 10/? [00:39&lt;00:00,  3.26s/it]"
          }
        },
        "aa09fb39dbf749d0a10e490fd38db234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9738d947068f4a4596063867b101b8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708ee827c7a24b04b73afaeb0dff77fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86806805c3a241a0a181190d0e69933c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "713706119e0c462f8f4bb6af5d5ecb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7acc5aa7623d4826aba59e15441b198c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd514be89034afb99f9e2873c91ba4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}